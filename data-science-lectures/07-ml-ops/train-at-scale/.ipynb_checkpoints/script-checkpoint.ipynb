{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0225b70-68bd-41c7-b6c7-68fc4969af20",
   "metadata": {},
   "source": [
    "# Train at Scale (eng)\n",
    "\n",
    "# ML Ops Module\n",
    "\n",
    "Hello everyone. Welcome to the new Machine learning operations module, the famous ML Ops, where you're going to learn to get out of your Jupyter notebooks and, uh, get your hands dirty with code vs code and data engineering a bit more.\n",
    "\n",
    "# 🚗 Welcome to WagonCab 🚗\n",
    "\n",
    "So welcome to Wagon Cab. You've just been hired as a machine learning engineer to this, uh, great Uber like company, an Uber competitor made by LW. And, we will see that you're going to have new responsibilities and the challenges of the five units that are associated to this MLOps module are going to revolve around the same business case, much like your decision science module, and you're going to be a machine learning engineer for the five units. But exaclty what is a machine learning engineer? \n",
    "\n",
    "# But what is a ML Engineer, exactly?\n",
    "\n",
    "The emergence of specialized roles in data jobs has led to the creation of new positions. Companies used to employ data scientists skilled in mathematics, statistics, machine learning, deep learning, and AI, as well as data engineers who constructed data pipelines. These pipelines were designed to make data accessible to data scientists, gathering information from various sources and feeding it into a central database.\n",
    "\n",
    "Data engineers were also responsible for creating distributed storage systems. If the data was too large to be stored on a single computer or on a single server, it would need to be distributed across multiple clusters in the cloud. The same applied to computing power, which sometimes had to be distributed across multiple servers to provide sufficient CPUs and GPUs.\n",
    "\n",
    "There was some overlap between these two roles and because of that, both had to communicate effectively and have a basic understanding of programming, with data engineers usually having a stronger focus on development than data scientists. The main challenge was facilitating effective communication between these two roles.\n",
    "\n",
    "# But what is an ML Engineer, exactly?(2)\n",
    "\n",
    "Machine learning is becoming a key business unit in many companies, and the role of a machine learning engineer is emerging as an intermediary position. These engineers take models designed by data scientists in isolated environments and operationalize them. This involves putting the models into production on servers that customers can use to request predictions. It's crucial to ensure that these models have longevity and don't degrade in performance over time.\n",
    "\n",
    "The concept of a model's lifecycle is a new development in machine learning. Models are now seen as data products that have a lifecycle, rather than simply being research products. Machine learning engineers are needed to oversee this lifecycle. They need to communicate effectively between data scientists and engineers.\n",
    "\n",
    "# 💡 It's also emerging as **tools** become more mature\n",
    "\n",
    "The role of a machine learning engineer is becoming increasingly possible due to the emergence and maturity of various tools designed to assist them. However, we won't delve into the expansive machine learning stack in detail during this bootcamp. But we are still going to provide a snapshot of the bigger picture, so that we can offer you guys some resources for further learning.\n",
    "\n",
    "The machine learning infrastructure is growing rapidly, with hundreds of companies pushing to develop both open-source and proprietary solutions. To navigate this landscape, let's consider a few examples.\n",
    "\n",
    "The process begins with data sources like databases, APIs, or live streams. This data needs to be collected using a workflow manager like Airflow or Prefect (and we are going to learn how to use prefect in the automate model lifecycle class, if im not mistaken). So these tools trigger the retrieval of new data as it arrives and manage consecutive or parallel tasks, resulting in a database for machine learning use.\n",
    "\n",
    "Once you've gathered these data sources into a database, you can use data science libraries like numpy and pandas for pre-processing - and we do this on platforms like Jupyter Notebook, Google AI workbench, or Databricks.\n",
    "\n",
    "Then you code your model using machine learning frameworks like Keras, TensorFlow, or scikit-learn. However, for handling large data, you might need distributed processing tools like Spark or Dask.\n",
    "\n",
    "Once you've developed a satisfactory model, you store it in a model registry. Large companies like Netflix may have hundreds or even thousands of models in production simultaneously. These models are deployed on servers using tools like TensorFlow or your custom server. Once deployed, they can be accessed by clients through APIs or app frameworks like Fast API or Django.\n",
    "\n",
    "However, over time, your model's performance may decrease due to changes in real-world conditions. Thus, it's crucial to monitor your model's performance and lifecycle, triggering new training or experiments as needed to maintain its efficiency.\n",
    "\n",
    "In addition to all of this, some companies are pushing for local machine learning solutions that simplify the process for basic models and cases. Tools like Data IQ or Google AutoML are examples of such platforms.\n",
    "\n",
    "Remember, the scope of available tools is too vast for anyone to know them all, and there's always a trade-off between using existing tools and creating custom solutions. Throughout this module, we'll experiment with both, starting with a manual approach to building a machine learning model lifecycle and gradually introducing tools to streamline the process.\n",
    "\n",
    "# **🚗 Back to `WagonCab` 🚗**\n",
    "\n",
    "That introduction may have been a bit daunting, but it's crucial to understand that a machine learning engineer is a distinct profession. This role requires the skills of a data scientist and that of a data engineer. But now, let's go back to the  Wagon Cab scenario, where you've been hired as a machine learning engineer. The company is developing a new machine learning product called Taxi Share. It aims to predict the real-time cost of a conventional taxi ride from point A to point B. This is because Wagon Cab, a competitor to Uber, wants to display on their app how much customers could save by using their service instead of a traditional taxi. So, you need to anticipate your competitor's prices and display them on your app. So basically, this is a machine learning product designed to predict prices.\n",
    "\n",
    "# `WagonCab` has the huge, public [NYC Trip Record Dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) at its disposal, which is around 170GB in size, and looks as follows\n",
    "\n",
    "Alright, so an extremely large New York trip record dataset, which is roughly 170GB, is available for use. The dataset appears to have only six or seven columns. The objective is to predict the total fare amount in dollars. The available features include the time the cab was called, the pickup and drop-off locations, and the number of passengers in the trip. There are hundreds of millions of these rows.\n",
    "\n",
    "So….A team of data scientists has previously developed a machine learning model to predict taxi prices. This model, built with TensorFlow, was created in a notebook context and trained on a small subset of the 170GB data, say, around 100K rows, to make it manageable for the data scientist's computer.\n",
    "\n",
    "Your role, however, is to train this model on all the rows in the dataset. The model has already been fine-tuned, so there's no need to adjust any hyperparameters or make changes to its architecture. This isn't part of your job as a machine learning engineer. okay?\n",
    "\n",
    "# 🎯 Your goal as an **ML engineer** will be to:\n",
    "\n",
    "Your task is to train this notebook at scale. This may involve transitioning it from a notebook context to a full-fledged Python project, capable of handling 170GB of data. To do this effectively, you will need to leverage cloud-based CPUs and GPUs. Larger or even multiple computers may be necessary to manage this volume of data. Remember, the more data you have, the better your model's performance., right?\n",
    "\n",
    "Once the model is trained, you will deploy it to a Linux server that's always on, ready to receive API calls, like call that requests the price of a particular item in a specific region. You'll need to manage the model's lifecycle performance as well. Monitor whether the performance is increasing or decreasing and decide when to retrain the model, especially as data drifts over time. Because data does drift right? Taxi fare prices may have increased in the past three months, so if that happends, it is definitely time to retrain your model.\n",
    "\n",
    "Finally, you'll need to create a user interface dashboard to display the results of your predictions. Although this might typically fall outside the responsibilities of a machine learning engineer, for this bootcamp, we want you to complete this module with a user-friendly app interface.\n",
    "\n",
    "# **Unit 1) Train at Scale**\n",
    "\n",
    "Let's begin with module one: Training at Scale. As a machine learning engineer, your goal is to:\n",
    "\n",
    "1. Understand the data scientist's notebook containing all the models. You'll read through the notebook and gain a thorough understanding of its contents.\n",
    "2. Package the notebook's code into a Python package. We'll discuss what this entails in today's lecture in more detail.\n",
    "3. Master your VSCode integrated development environment. As we leave Jupyter behind, we'll focus on using VSCode to code more efficiently. I'll provide you with tips and tricks to help you become a more effective developer.\n",
    "4. Learn how to use incremental processing techniques to handle large amounts of data. These are techniques the data scientist did not cover.\n",
    "\n",
    "Today's lecture will primarily focus on packaging your code and mastering your IDE.\n",
    "\n",
    "# **1) Packaging & Virtual Env 101**\n",
    "\n",
    "So let's start. That was just the introduction. So today we are going to create a dummy package together step by step, and you will see what a Python package really is, how to install it,how to use it and why. So soemtime it is better to use packages instead of notebooks.\n",
    "\n",
    "# **1.1) What is a Package? (3)**\n",
    "\n",
    "A package is reusable code that can be transferred from one project to another. For instance, scikit-learn is a package that you can import from linear model. This is highly convenient as it eliminates the need to manually copy and paste raw code into your analysis. Instead, you can simply import it.\n",
    "\n",
    "Packages can be shared with others and to do this, you can either publish it to PyPI, making it publicly available, or host it on your GitHub page. Regardless of where it's hosted, others can pip install your package directly. If it's on GitHub, you can publish it and others can pip install it directly using the GitHub URL of your package.\n",
    "\n",
    "Another advantage of having a Python package instead of a notebook is that you can track your code with git. This is particularly useful when dealing with Jupyter notebooks or similar files, where it's difficult to differentiate between versions. I don’t know if you guys have ever tried to do a git diff on a jupyter notebook, but the result is this awfuly confusing json file.\n",
    "\n",
    "So today we will build a dummy package called 'Toto', which you will be able to install with pip, cool right. So you will be able to pip install toto on your machine.\n",
    "\n",
    "# **Anatomy of a Minimal Python Package(3)**\n",
    "\n",
    "What comprises a minimal python package? You only need these files:\n",
    "\n",
    "1. **Project Directory**: The project directory name can be anything, as it's just the relative root path of everything else. \n",
    "2. **[Setup.py](http://setup.py/)**: This is the instruction for the pip install command. When you use the pip install command, you must be at the root where [setup.py](http://setup.py/) is located. This file will be executed during the installation.\n",
    "3. **Toto**: This is where you code your Python logic. You create a folder named 'Toto' (if you want your package name to be 'toto'). This folder becomes a package when you put an [init.py](http://init.py/) file inside. Without [init.py](http://init.py/), 'Toto' is just a folder; with [init.py](http://init.py/), it becomes a package.\n",
    "4. **toto/lib.py**: When you put any Python file inside a package, like [lib.py](http://lib.py/), that file becomes a module. A module is a single Python file inside a package, and a package is a directory with an [init.py](http://init.py/) file inside. With [init.py](http://init.py/) in a folder, you can call 'toto.lib', because 'lib' is now a module inside a package. So you'll be able to run this file from your command line terminal. So when you execute this path - 'python toto/lib.py', you are basically saying, 'execute me as a module, the module toto.lib'. This is a better way to work, as it's what you do when you import any Python file.\n",
    "5. **[Init.py](http://init.py/)**: You can mostly leave [init.py](http://init.py/) empty. It gets executed whenever you import from 'toto'. If you need something to be executed every time you import it, feel free to add something inside [init.py](http://init.py/).\n",
    "\n",
    "# 💻 **LIVECODE: minimal package**\n",
    "\n",
    "So let’s build our toto project:\n",
    "\n",
    "```python\n",
    "mkdir project-toto\n",
    "cd project-toto\n",
    "mkdir toto\n",
    "touch toto/lib.py\n",
    "touch toto/__init__.py\n",
    "touch setup.py\n",
    "code .\n",
    "```\n",
    "\n",
    "explain each file and folder.\n",
    "\n",
    "**`setup.py`** is a script used in Python projects for packaging and distributing the project. It typically contains metadata about the project such as its name, version, dependencies, and other information necessary for installation. It is the instruction for the pip install command. When you use the pip install command, you must be at the root where [setup.py](http://setup.py/) is located. This file will be executed during the installation.\n",
    "\n",
    "All right. Now I want to write something in the [lib.py](http://lib.py/) just so we can debug it together. And in the [lib.py](http://lib.py/), I am going to simply write, uh, a method that says, hello, my name is Jean. And if I call my package. If I call my package from the command line terminal, it should just execute. Hello, my name is Jean. \n",
    "\n",
    "```python\n",
    "# toto/lib.py\n",
    "def who_am_i():\n",
    "    print(\"Hello my name is Jean\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    who_am_i()\n",
    "```\n",
    "\n",
    "This Python code defines a function `who_am_i()` and then checks if the script is being run directly or if it's being imported as a module. Let's break it down:\n",
    "\n",
    "```python\n",
    "def who_am_i():\n",
    "    print(\"Hello my name is Jean\")\n",
    "```\n",
    "\n",
    "This part of the code defines a function called `who_am_i()`. When this function is called, it prints \"Hello my name is Jean\" to the console.\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    who_am_i()\n",
    "```\n",
    "\n",
    "Here, the code checks if the `__name__` variable is equal to `'__main__'`. If it is, it means the script is being run directly, not imported as a module. In that case, the function `who_am_i()` is called, and it prints \"Hello my name is Jean\" to the console.\n",
    "\n",
    "So, when you run this script directly from the command line or an IDE, it will print \"Hello my name is Jean\". However, if you import this script as a module into another script, the `if __name__ == '__main__':` condition will evaluate to `False`, and the `who_am_i()` function will not be executed automatically. This allows you to use the `who_am_i()` function within other scripts without it being called automatically when the script is imported.\n",
    "\n",
    "we can also call:\n",
    "\n",
    "```python\n",
    "python -m toto.lib\n",
    "```\n",
    "\n",
    "In Python, the `-m` flag is used to run a Python module as a script. When you run `python -m <module_name>`, Python searches for the specified module in the Python path and executes it as the main module.\n",
    "\n",
    "# **1.2) Virtual Environments**\n",
    "\n",
    "We're initiating a package and planning to add more code inside. We might consider adding TensorFlow to our package rather than just a print statement. However, TensorFlow is three gigabytes when unzipped, which can be bulky if you want to share this package with someone else. If you don't need TensorFlow, and perhaps only need print statements or scikit-learn, which are lighter, it doesn't make sense to include every package on your computer. When sharing a package, it's important to minimize unnecessary dependencies. So, if you won't be using TensorFlow, there's no need to include it in the package.\n",
    "\n",
    "# **💻 Let's create a dedicated virtual env `totoenv` for this project**\n",
    "\n",
    "So if i do a pip list you will see all the packages that i have inside m LW environment. and we really dont need all of this inside out tiny toto project. So Im gonna create a new one just for toto:\n",
    "\n",
    "```python\n",
    "pyenv virtualenv 3.10.6 batch-1542\n",
    "pyenv local batch-1542\n",
    "pip list\n",
    "```\n",
    "\n",
    "Package    Version\n",
    "\n",
    "---\n",
    "\n",
    "pip        24.0\n",
    "setuptools 63.2.0\n",
    "\n",
    "**`pip`** is the standard package manager for Python. It is used to install and manage Python packages from the Python Package Index (PyPI)\n",
    "**`setuptools`** is a package development library in Python that provides tools for creating and distributing Python packages. \n",
    "\n",
    "Now, I have a python-version file inside my project. The Python version is visible every time it's read. This should switch my virtual environment to \"batch-1542\". Notice that if I leave my project directory, my env changes back to my global env LW and when i go back to the project directory, it takes me back to batch-1542 environment.\n",
    "\n",
    "# **Install minimal packages for this demo lecture**\n",
    "\n",
    "For the purpose of this class, I'm going to use pip to install pandas, IPython, and ipykernel. IPython is used for writing in the terminal and ipykernel is used for opening notebooks. \n",
    "\n",
    "So if I do pip list now I got all these packages here. But I only installed 3 libraries…. can anybody tell me why i have so many packages? Dependencies.\n",
    "\n",
    "Explain picture.\n",
    "\n",
    "# **2) 💻 Installing & Using a Package**\n",
    "\n",
    " So I installed pandas and IPython, ipykernel now  let’s go ahead and install my package that I created toto.\n",
    "\n",
    "# **2.1) Install the Package**\n",
    "\n",
    "if I do `pip list | grep toto` i wont find it installed but if I do pandas it will. grep here guys is used to search for patterns within text files or output streams. So, **`pip list | grep pandas`** effectively filters the output of **`pip list`** to only show lines containing the word \"pandas\", which is useful for quickly identifying whether a specific package is installed, especially when you have a big list like we do right now.\n",
    "\n",
    "To install the 'toto' package, you need to use pip to install your [setup.py](http://setup.py/). This can be done by using the command 'pip install .' while located at the root directory where your setup file is located. However, please note that the file is currently empty. The instructions within the setup file dictate the actions to be performed during installation. So, what do these instructions entail?\n",
    "\n",
    "The instructions are straightforward and follow standard Python syntax. Essentially, you need to import the \"setup\" module from the standard Python library. You will use this when executing this [setup.py](http://setup.py/).\n",
    "\n",
    "```python\n",
    "# setup.py\n",
    "from setuptools import setup\n",
    "\n",
    "setup(name='toto',\n",
    "      description=\"package description\",\n",
    "      packages=[\"toto\"]) # You can have several packages, try it\n",
    "```\n",
    "\n",
    "**Install**\n",
    "\n",
    "Sit next to `setup.py` and run:\n",
    "\n",
    "`pip install .`\n",
    "\n",
    "**Verify that the package is installed**\n",
    "\n",
    "`pip freeze`\n",
    "\n",
    "**`pip list`** lists all installed Python packages in a simple, human-readable format.\n",
    "\n",
    "**`pip freeze`** produces a list of all installed packages and their exact versions in a format that is suitable for saving to a requirements.txt file.\n",
    "\n",
    "# **2.2) Run the Package from Anywhere (when `totoenv` is Activated)**\n",
    "\n",
    "**For instance, from a notebook**\n",
    "\n",
    "`mkdir notebooks\n",
    "touch notebooks/notebook.ipynb`\n",
    "\n",
    "Open the notebook with VS Code, select `ipykernel=totoenv`, and you should be able to call\n",
    "\n",
    "**`from** toto.lib **import** who_am_i\n",
    "who_am_i()`\n",
    "\n",
    "# ❓ **Why Does it Work?**\n",
    "\n",
    "🔎 Well, remember that Python's `import` always looks at your `PYTHONPATH`\n",
    "\n",
    "**`import** sys\n",
    "sys**.**path`\n",
    "\n",
    "Which pyenv always appends with site-packages:\n",
    "\n",
    "👉 *~/.pyenv/versions/3.8.12/envs/**totoenv**/lib/python3.8/**site-packages***\n",
    "\n",
    "🔎 ...and where is `toto` located?\n",
    "\n",
    "**`import** toto\n",
    "toto**.**__file__`\n",
    "\n",
    "👉 ~/.pyenv/versions/3.8.12/envs/**totoenv**/lib/python3.8/**site-packages**/toto/__init__.py\n",
    "\n",
    "✅ `pip install .` creates a **COPY** of your project folder inside site-packages\n",
    "\n",
    "# site-packages contains all your pip packages.\n",
    "\n",
    "`site-packages` is a directory in your Python environment where pip installs Python packages. When you use `pip` to install packages, they are typically installed into this directory.\n",
    "\n",
    "A few observations about `site-packages`:\n",
    "\n",
    "1. `site-packages` is usually located within your Python installation directory. The exact path may vary depending on your operating system and Python installation method. \n",
    "2. It contains directories and files for each installed Python package. Each package has its own directory within `site-packages`, and this directory usually contains the Python modules, as well as any other files necessary for the package to function.\n",
    "3. When you install packages using `pip` without using a virtual environment, they are installed into the global `site-packages` directory. However, when you create and activate a virtual environment, `pip` installs packages into a `site-packages` directory specific to that virtual environment, keeping dependencies isolated from the global environment.\n",
    "\n",
    "# **🔥 Hot-Reload on the Package?(3)**\n",
    "\n",
    "Let's explore hot reloading by updating our code to see if the changes appear. I'll use my notebook, which I'll place on my right. You'll see me modify the code. For instance, if I enter \"Hello, my name is Tatchi\", and then rerun the code, the change isn't reflected.\n",
    "\n",
    "Why is this happening? Remember, when I used pip install, it created a copy of the current state of the code in my package. So, pip install doesn't reflect ongoing development changes. To see your changes during development, you need to use pip install with the -e flag instead.\n",
    "\n",
    "**✅ `pip install -e .` (editable) for hot-reloading**\n",
    "\n",
    "- First, `pip uninstall toto` (move away from `setup.py`'s root to do it properly)\n",
    "- Then `pip install -e .`\n",
    "\n",
    "**`import** toto\n",
    "toto**.**__file__ *# '~/code/sandbox/project-toto/toto/__init__.py'*`\n",
    "\n",
    "PS.: for notebooks and `ipython`, don't forget the magic command to avoid closing/reopening `ipython` every time\n",
    "\n",
    "**`%**load_ext autoreload\n",
    "**%**autoreload 2`\n",
    "\n",
    "🔥 **Pro Tip**: setup `autoreload` as default action\n",
    "\n",
    "*`//settings.json*\"jupyter.runStartupCommands\"**:** [\n",
    "  \"%load_ext autoreload\",\n",
    "  \"%autoreload 2\"\n",
    "],`\n",
    "\n",
    "# **2.3) Dependencies**\n",
    "\n",
    "**👉 Let's say we want the `termcolor` package to be installed along with `toto`**\n",
    "\n",
    "```python\n",
    "# toto/lib.py\n",
    "from termcolor import colored\n",
    "\n",
    "def who_am_i():\n",
    "    print(colored(\"Hello my name is Jean\", \"blue\"))\n",
    "```\n",
    "\n",
    "Devemos fazer um pip install termcolor?\n",
    "\n",
    "✅ **Solution: create `requirements.txt` and update `setup.py`**\n",
    "\n",
    "*`# Terminal*\n",
    "touch requirements.txt\n",
    "echo termcolor >> requirements.txt` \n",
    "\n",
    "```python\n",
    "# setup.py\n",
    "from setuptools import setup\n",
    "from setuptools import find_packages\n",
    "\n",
    "# list dependencies from file\n",
    "with open('requirements.txt') as f:\n",
    "    content = f.readlines()\n",
    "requirements = [x.strip() for x in content]\n",
    "\n",
    "setup(name='toto',\n",
    "      description=\"package description\",\n",
    "      packages=find_packages(), # NEW: find packages automatically\n",
    "      install_requires=requirements) # NEW\n",
    "```\n",
    "\n",
    "Having a `requirements.txt` file is beneficial for several reasons:\n",
    "\n",
    "1. **Reproducibility**: It helps ensure that your project's dependencies are consistent across different environments. By specifying exact versions of each package, you can recreate the same environment on different machines or at different times.\n",
    "2. **Dependency Management**: It makes it easy for other developers to set up your project by installing the required dependencies with a single command. They can use `pip install -r requirements.txt` to install all the necessary packages.\n",
    "3. **Collaboration**: When collaborating on a project, having a `requirements.txt` file ensures that everyone is using the same versions of dependencies. This minimizes potential issues due to version mismatches.\n",
    "4. **Documentation**: It serves as documentation for your project's dependencies. Anyone looking at your project can easily see what packages are required and their versions.\n",
    "\n",
    "Overall, having a `requirements.txt` file is a best practice for Python projects as it facilitates consistency, reproducibility, and collaboration.\n",
    "\n",
    "# TREE\n",
    "\n",
    "**2.4) Adding a `Makefile` to Create Simple CLI Commands ⚡️**\n",
    "\n",
    "A Makefile is a special file used to automate the process of building and compiling projects. It contains instructions, called rules, that define how to build specific targets (usually executable files) from source code files.\n",
    "\n",
    "**Makefile Sample**\n",
    "\n",
    "💻 Let's run a directive; while sitting next to the `Makefile`:\n",
    "\n",
    "`tree\n",
    "make clean\n",
    "tree`\n",
    "\n",
    "Let's run several directives; while sitting next to the `Makefile`:\n",
    "\n",
    "`make install clean *# = make all*`\n",
    "\n",
    "# **3) Testing your Package 🧪**\n",
    "\n",
    "```python\n",
    "💻 Test Example\n",
    "# toto/divide.py\n",
    "def divide_without_raising(x:float, y:float) -> float:\n",
    "    '''\n",
    "    divides x by y, but instead of raising errors when y equals 0, returns:\n",
    "    - inf if x positive\n",
    "    - -inf if x negative\n",
    "    - nan if x equals 0\n",
    "    '''\n",
    "    pass # YOUR CODE HERE\n",
    "```\n",
    "\n",
    "# Small parentheses regarding `inf` and `nan`\n",
    "\n",
    "Let's talk a bit about infinity in Python. We'll start by creating a float variable called 'infinity'. This is a standard naming convention, but it can be changed. 'Infinity' is a specific float type in Python or NumPy. If you assert the type of 'infinity' as float, it will return true.\n",
    "\n",
    "The 'assert' command in Python is used for debugging purposes. If the condition stated after 'assert' is true, it does nothing and the program continues. If the condition is false, it raises an AssertionError.\n",
    "\n",
    "In this case, we're asserting that 'infinity' equals itself, which is true. Adding 'infinity' to itself or multiplying 'infinity' by itself still results in 'infinity'. However, if you multiply 'infinity' by -1 or any negative number, it becomes negative infinity.\n",
    "\n",
    "One thing to note is that subtracting 'infinity' from 'infinity' or dividing 'infinity' by 'infinity' doesn't result in an error. Instead, it returns 'NaN', which stands for 'Not a Number'.\n",
    "\n",
    "'NaN' is another special float type in Python. It's unique in that it's the only float that doesn't equal itself. To check if a number is 'NaN', you can use the 'math.isnan()' function.\n",
    "\n",
    "Remember that any operation with 'NaN' will return 'NaN'. Once you have a 'NaN', you cannot perform any operation to get a non-'NaN' number.\n",
    "\n",
    "# Let's do **TDD**: write tests before coding the function\n",
    "\n",
    "1. **test_has_correct_arithmetic()**:\n",
    "    - This test checks whether the `divide_without_raising` function correctly performs basic arithmetic operations.\n",
    "    - It asserts that when dividing 2.0 by 2.0, the result is 1.0.\n",
    "    - If the result is not 1.0, it raises an assertion error with the message 'wrong basic arithmetic'.\n",
    "2. **test_handles_divide_by_zero_correctly()**:\n",
    "    - This test suite verifies the behavior of `divide_without_raising` when dividing by zero.\n",
    "    - The first assertion checks that dividing a non-zero number (2.0) by zero results in positive infinity (`float('inf')`).\n",
    "    - The second assertion checks that dividing a non-zero number (-2.0) by zero results in negative infinity (`1 * float('inf')`).\n",
    "    - The third assertion checks that dividing zero by zero results in NaN (Not a Number), which is a special floating-point value to represent undefined or indeterminate results. It uses `math.isnan()` to verify that the result is NaN.\n",
    "\n",
    "Overall, these test cases ensure that the `divide_without_raising` function behaves correctly in terms of basic arithmetic and correctly handles division by zero cases, producing expected results or special values such as infinity and NaN as appropriate.\n",
    "\n",
    "We need to install pytest which we don’t have. And how do I install pytest now guys? Put it in the requirements.\n",
    "\n",
    "Now, I'm running pytest to test my toto.divide function. This will execute the test file and generate the results. As you can see, the arithmetic test passed, which means my basic arithmetic works well. However, it failed to handle zero correctly. By examining the test error, it shows that when x equals two and y equals zero, it raised a zero division error. It couldn't compute or complete the assertion because it broke before it could be evaluated as true or false. This indicates that the function may break when y equals zero, something I should address.\n",
    "\n",
    "```python\n",
    "    if y != 0.:\n",
    "        return x/y\n",
    "    else:\n",
    "        if x > 0.:\n",
    "            return float('inf')\n",
    "        if x < 0.:\n",
    "            return -1 * float('inf')\n",
    "        if x == 0.:\n",
    "            return float('nan')\n",
    "```\n",
    "\n",
    "# **🏁 Lastly: add a `README.md` to help reproduce your work!**\n",
    "\n",
    "Here is a short example of a readme guys, but a [README.md](http://readme.md/) should provide clear instructions on how to set up the environment, run the tests, and understand the purpose of the tests. It also includes information on contributing and licensing of the project. You can customize it further based on your specific requirements and project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a069b2-0f09-4d0c-b657-9395f133c276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
