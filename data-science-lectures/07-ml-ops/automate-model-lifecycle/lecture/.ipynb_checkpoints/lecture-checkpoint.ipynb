{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc219386-36b0-491f-86a5-cfd08d529755",
   "metadata": {},
   "source": [
    "# Automate Model Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa944a-0972-436a-9181-349fedf64b21",
   "metadata": {},
   "source": [
    "Automating the model lifecycle refers to streamlining and automating the stages involved in developing, deploying, and maintaining machine learning models. Some of these steps are: \n",
    "- data preprocessing,\n",
    "- model training,\n",
    "- evaluation, \n",
    "- deployment, \n",
    "- monitoring, \n",
    "- and retraining. \n",
    "\n",
    "Automating these processes can save time, improve efficiency, and ensure consistency in model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7582e8-84ba-48d7-81af-dc6e8383e847",
   "metadata": {},
   "source": [
    "# Lecture plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3a101-3806-4547-9e96-c2a9d2cb19e1",
   "metadata": {},
   "source": [
    "# Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ec494-de54-4169-95c5-c624ab76be75",
   "metadata": {},
   "source": [
    "#### Google Cloud Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6bdc6-fce6-4317-8d55-ce47cc6a780c",
   "metadata": {},
   "source": [
    "#### Cloud Storage\n",
    "\n",
    "In BigQuery, columnar storage and partitioning are two important features that can significantly improve query performance and cost efficiency when working with large datasets.\n",
    "\n",
    "So what are these things?\n",
    "\n",
    "`Columnar Storage`:\n",
    "BigQuery utilizes a columnar storage format called Capacitor (formerly known as Capacitor Bigtable), which organizes data by column rather than by row. In a columnar storage format, values of each column are stored together, allowing for more efficient compression and better data compression ratios. This format enables BigQuery to scan and process only the specific columns needed for a query, minimizing the amount of data read from storage. <br>\n",
    "`Partitioning` is a technique that divides a table into smaller, more manageable sections based on a specific column's values. BigQuery supports partitioning tables based on time and date, also called ingestion-time partitioning) or date/timestamp partitioning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6575ecf8-6947-411e-ad9a-c0a422b07fe3",
   "metadata": {},
   "source": [
    "#### Compute Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d8a5e-a049-4a2c-8771-c63c06da97aa",
   "metadata": {},
   "source": [
    "#### direnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0afad7-58f7-4f43-9c92-af8a49b18206",
   "metadata": {},
   "source": [
    "direnv is a command-line tool designed to manage environment variables ia a directory basis. It helps us automate the loading and unloading of environment variables based on the current working directory. CURIOSITY: The name \"direnv\" is short for \"directory environment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd6302-3cf4-41be-aad5-0b1df394ac3e",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023617dd-082e-4130-83d2-757a35e63603",
   "metadata": {},
   "source": [
    "### What is our progress?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6fa4a-75cf-47e4-b9e8-906dd808727d",
   "metadata": {},
   "source": [
    "# What's next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6296b0a8-87a6-4f81-a6aa-31af4ed04ea1",
   "metadata": {},
   "source": [
    "So the way that it is right now is that someone has to log into your virtual machine and manually run make run train, manually re-prepreocess the data to have it up to date so in the longrun it's an unrealistic prospect, you see with one model it may be ok, someone can do that but everytime you add a new model you need to maintain it becomes cumbersome.\n",
    "\n",
    "That is why we need to **Create a robust model lifecycle** - to:\n",
    "- Ensure the reproducibility of the training in the future\n",
    "- Track the performance of the model over time\n",
    "- Serve multiple versions of the model\n",
    "- Automate the model lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922fa87-2685-43bb-8f76-85fb71661d31",
   "metadata": {},
   "source": [
    "# Robust Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1ddad-27d7-4223-b419-64e0f3008389",
   "metadata": {},
   "source": [
    "# Experiment tracking with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb5be1-5ab7-4185-b7b3-9232cf259b7e",
   "metadata": {},
   "source": [
    "MLflow is an open-source platform that enables machine learning experiment tracking, reproducibility, and model management. And what its gonna do for us is help track our experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a53794-dee3-4ba8-a0f0-3af31dddd38b",
   "metadata": {},
   "source": [
    "Yesterday we were sitting with this workflow -> we had out data warehouse that was passing preprocessed data to our virtual machine which was then passing on the data, that is our model to google cloud storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711100f0-548a-45d7-af29-a08ebdbdaa79",
   "metadata": {},
   "source": [
    "Now we want to track the experiment and that is gonna come with a few things:\n",
    "- data version: refers to the data used for the training, in our case we are gonna be looking at the datetime or the timestamp and the number of rows which the past couple of days we have been working with 1K, 200K or all.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf537e5-df02-434c-a6f0-bbfbf04fde93",
   "metadata": {},
   "source": [
    "- as experiment parameters:\n",
    "1. code version\n",
    "2. Code parameters (learning rate, epocs, eetc...)\n",
    "3. training env: which is python + package versions\n",
    "4. Preprocessing type: what we used to preprocess the data\n",
    "5. the model hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfa462-4a1e-4375-9c06-b21ef2ab6b7c",
   "metadata": {},
   "source": [
    "- as experiment metrics:\n",
    "1. training metrcis: your loss, you mae, your accuracy and so on...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6780b4c-ac7a-4b64-98ef-bb59d37c8ef1",
   "metadata": {},
   "source": [
    "- then finally the model version, the actual model itself. like V1 trained on may 25, V2 trained on may 30th and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab3a12-16b2-4ebc-b1dd-f27571947c77",
   "metadata": {},
   "source": [
    "As you can see there are quite a lot of things that we wanna keep track  of and if we were doing it just by ourselves in python it would involve writing tons and tons of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6297a2e-2a5e-4366-be20-c9348d115a3a",
   "metadata": {},
   "source": [
    "# How to track our experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb7ef78-675f-4782-aecb-b78926a03da4",
   "metadata": {},
   "source": [
    "So what we are gonna have instead of having to write all that code is an MLflow server. and this server will:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1884a-76f4-4347-ae09-26b22345b3a0",
   "metadata": {},
   "source": [
    "-> GO TO ROADMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea71599-97c4-4e3a-9244-f8b2a171042e",
   "metadata": {},
   "source": [
    "-> BACK ON SLIDE: THEORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77481557-2708-4c61-8306-076d14e623d7",
   "metadata": {},
   "source": [
    "# CHART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b40df-47da-43db-9703-f9ee51621e39",
   "metadata": {},
   "source": [
    "# ML Flow Server Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387ae32-e924-412a-ad07-2c056831e339",
   "metadata": {},
   "source": [
    "So this is how it is structured behind the scenes. So there is a remote host that has ML Flow running on it and it'll be connected to a SQL database that will store the metrics and parameters. But a SQL DB is not a proper way to store a model so behind the scenes it is using a bucket to store the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5234140-cfe9-4ec0-ba3a-960390385b8a",
   "metadata": {},
   "source": [
    "# Automate the model lifecycle with prefect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb34cb-bf5c-4495-859f-b7e78865c799",
   "metadata": {},
   "source": [
    "#### Manual trigger\n",
    "at the moment we still need to login to our VM or do it locally but we still need to manually run make run train\n",
    "\n",
    "#### Model Lifecycle\n",
    "but what we want is - to breakdown the models lifecycle. based on the lecture today, on the dates that we were using, im presuming we wanna train our model every montl. so in order to do that we need to get fresh data and check our model's performance on the new data. do we wanna retrain? do we wanna sent it to production?\n",
    "\n",
    "#### get fresh data\n",
    "so in order to do that we need to get fresh data, we need to preprocess it and push it to our data warehose\n",
    "\n",
    "#### evaluate model performance\n",
    "so what we wanna do here is look at the past performance of the model so in order to do that we pull our new data from the warehouse, and run an evaluation on our model with the new data\n",
    "\n",
    "#### retrain model\n",
    "we'll retrain the model it should happen on a VM but it can happen locally as well\n",
    "\n",
    "#### mark model for production\n",
    "and from that we want to compare the performance of the model and then maybe mark it for production\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406635b-00a1-4d30-b2d5-6175f21c31f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
