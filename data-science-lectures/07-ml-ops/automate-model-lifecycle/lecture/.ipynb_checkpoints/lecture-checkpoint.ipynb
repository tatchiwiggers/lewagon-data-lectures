{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc219386-36b0-491f-86a5-cfd08d529755",
   "metadata": {},
   "source": [
    "# Automate Model Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa944a-0972-436a-9181-349fedf64b21",
   "metadata": {},
   "source": [
    "Automating the model lifecycle refers to streamlining and automating the stages involved in developing, deploying, and maintaining machine learning models. Some of these steps are: \n",
    "- data preprocessing,\n",
    "- model training,\n",
    "- evaluation, \n",
    "- deployment, \n",
    "- monitoring, \n",
    "- and retraining. \n",
    "\n",
    "Automating these processes can save time, improve efficiency, and ensure consistency in model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7582e8-84ba-48d7-81af-dc6e8383e847",
   "metadata": {},
   "source": [
    "# Lecture plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3a101-3806-4547-9e96-c2a9d2cb19e1",
   "metadata": {},
   "source": [
    "# Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ec494-de54-4169-95c5-c624ab76be75",
   "metadata": {},
   "source": [
    "#### Google Cloud Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a1967-953a-4f57-a1ba-d12ce084b0d2",
   "metadata": {},
   "source": [
    "- Console vs CLI vs code\n",
    "- Authentication: one method for each interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389ee76-647f-4dfd-8c06-7581556849a3",
   "metadata": {},
   "source": [
    "Google Cloud Platform (GCP) provides multiple interfaces for interacting with its services and resources, including the Console (web-based graphical user interface), Command-Line Interface (CLI), and various SDKs (which allow interaction via code). Each of these interfaces requires authentication, and GCP offers different methods for authenticating in each interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6bdc6-fce6-4317-8d55-ce47cc6a780c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cloud Storage\n",
    "\n",
    "- Immutable data\n",
    "\n",
    "In Google Cloud Storage (GCS), blobs (binary large objects) are the fundamental units of data storage. They represent individual pieces of data stored in buckets. Tjey are Immutable because the data cannot be altered or deleted after it has been written.\n",
    "\n",
    "- Relational data\n",
    "- Columnar storage & partitions\n",
    "\n",
    "In BigQuery, columnar storage and partitioning are two important features that can significantly improve query performance and cost efficiency when working with large datasets.\n",
    "\n",
    "If they ask:\n",
    "\n",
    "`Columnar Storage`:\n",
    "BigQuery utilizes a columnar storage format called Capacitor, which organizes data by column rather than by row. In a columnar storage format, values of each column are stored together, allowing for more efficient compression and better data compression ratios. This format enables BigQuery to scan and process only the specific columns needed for a query, minimizing the amount of data read from storage. <br>\n",
    "`Partitioning` is a technique that divides a table into smaller, more manageable sections based on a specific column's values. BigQuery supports partitioning tables based on time and date, also called ingestion-time partitioning) or date/timestamp partitioning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6575ecf8-6947-411e-ad9a-c0a422b07fe3",
   "metadata": {},
   "source": [
    "#### Compute Engine\n",
    "\n",
    "we talked about the idea of a virtual machine,  which are an important building block of cloud computing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d8a5e-a049-4a2c-8771-c63c06da97aa",
   "metadata": {},
   "source": [
    "#### direnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0afad7-58f7-4f43-9c92-af8a49b18206",
   "metadata": {},
   "source": [
    "direnv is declared in the .env file and is a command-line tool designed to manage environment variables in a directory basis. It helps us automate the loading and unloading of environment variables based on the current working directory. CURIOSITY: The name \"direnv\" is short for \"directory environment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd6302-3cf4-41be-aad5-0b1df394ac3e",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023617dd-082e-4130-83d2-757a35e63603",
   "metadata": {},
   "source": [
    "### What is our progress?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6fa4a-75cf-47e4-b9e8-906dd808727d",
   "metadata": {},
   "source": [
    "# What's next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6296b0a8-87a6-4f81-a6aa-31af4ed04ea1",
   "metadata": {},
   "source": [
    "So the way that it is right now is that someone has to log into your virtual machine and manually run `make run_train`, manually re-prepreocess the data to have it up to date so in the longrun it's an unrealistic prospect, you see with one model it may be ok, someone can do that but - if everytime you add a new model you need to maintain it becomes cumbersome and pointless.\n",
    "\n",
    "That is why we need to **Create a robust model lifecycle** - to:\n",
    "- Ensure the reproducibility of the training in the future\n",
    "- Track the performance of the model over time\n",
    "- Serve multiple versions of the model\n",
    "- Automate the model lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922fa87-2685-43bb-8f76-85fb71661d31",
   "metadata": {},
   "source": [
    "# Robust Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1ddad-27d7-4223-b419-64e0f3008389",
   "metadata": {},
   "source": [
    "# Experiment tracking with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb5be1-5ab7-4185-b7b3-9232cf259b7e",
   "metadata": {},
   "source": [
    "MLflow is an open-source platform that enables machine learning experiment tracking, reproducibility, and model management. And what its gonna do for us is help track our experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a53794-dee3-4ba8-a0f0-3af31dddd38b",
   "metadata": {},
   "source": [
    "# CLoud Training\n",
    "\n",
    "Yesterday we were sitting with this workflow -> we had out data warehouse that was passing preprocessed data to our virtual machine which was then passing on the data, that is our model to google cloud storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711100f0-548a-45d7-af29-a08ebdbdaa79",
   "metadata": {},
   "source": [
    "# Experiment Tracking\n",
    "\n",
    "Now we want to track the experiment and that is gonna come with a few things:\n",
    "- data version: refers to the data used for the training, in our case we are gonna be looking at the datetime or the timestamp and the number of rows which the past couple of days we have been working with 1K, 200K or all.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf537e5-df02-434c-a6f0-bbfbf04fde93",
   "metadata": {},
   "source": [
    "- with experiment parameters:\n",
    "1. code version\n",
    "2. Code parameters: which is the learning rate, epochs, etc...\n",
    "3. training env: which is python + package versions\n",
    "4. Preprocessing type: which is what we used to preprocess the data\n",
    "5. the model hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfa462-4a1e-4375-9c06-b21ef2ab6b7c",
   "metadata": {},
   "source": [
    "- with experiment metrics:\n",
    "1. training metrcis: your loss, you mae, your accuracy and so on...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6780b4c-ac7a-4b64-98ef-bb59d37c8ef1",
   "metadata": {},
   "source": [
    "- then finally the model version, the actual model itself. like V1 trained on may 25, V2 trained on may 30th and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab3a12-16b2-4ebc-b1dd-f27571947c77",
   "metadata": {},
   "source": [
    "As you can see there are quite a lot of things that we wanna keep track  of and if we were doing it just by ourselves in python it would involve writing tons and tons of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ec7a0-95bf-45ce-bacb-ca65b0d43e03",
   "metadata": {},
   "source": [
    "# Tracking Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc2bd9-e394-46d3-9062-34bb4f921bc8",
   "metadata": {},
   "source": [
    "For tracking machine learning experiments using MLflow, you'll need to ensure you have the necessary infrastructure and practices in place to capture various aspects of your experiments effectively. Here are some of the requirements for tracking experiments using MLflow:\n",
    "\n",
    "1. **Experiment Params & Metrics**:\n",
    "   - **Code Version**: Record the version of the code used for training the model. This can be achieved by capturing the git commit ID, hash, or SHA of the code repository.\n",
    "   - **Code Parameters**: Document the parameters used in the code, such as input paths, output paths, and any other configurable settings.\n",
    "   - **Training Environment**: Include information about the Python version and package versions used for training the model. This ensures reproducibility by capturing the exact environment in which the model was trained.\n",
    "   - **Preprocessing Type**: Describe the preprocessing steps applied to the data before training the model. This may include data cleaning, feature engineering, scaling, etc.\n",
    "   - **Model Hyperparameters**: Record the hyperparameters used for training the model, such as learning rate, batch size, number of epochs, etc.\n",
    "   - **Training Metrics**: Log relevant training metrics, such as loss, accuracy, precision, recall, F1 score, etc., to evaluate the performance of the model during training.\n",
    "\n",
    "2. **Model Version**:\n",
    "   - **Persisted Trained Model**: Save the trained model artifacts, including the model architecture, weights, and any other necessary files required to reproduce the model.\n",
    "   - **Version Number**: Assign a unique version number or identifier to the trained model artifacts. This helps track different versions of the model over time.\n",
    "\n",
    "3. **Data Version**:\n",
    "   - **Data Used for Training**: It's good practice to keep track of the data used for training the model. This includes information such as the start date, end date, and the size of the dataset (e.g., 1k, 200k, or entire dataset).\n",
    "   - **Data Versioning Control**: DVC -> Consider using a data versioning tool like DVC to manage and track changes to your datasets. DVC integrates with Git and allows you to version control large datasets efficiently by storing only the changes (diffs) to the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adec8ac-b36c-4868-baea-b39a70688326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e73f29e8-af9d-486b-9ef8-8e35387a2c8a",
   "metadata": {},
   "source": [
    "To establish experiment tracking from a data warehouse to a virtual machine and finally to the experiment tracking system (such as MLflow), you'll need to design a workflow that captures and logs relevant information at each stage:\n",
    "\n",
    "1. Data Warehouse: In the data warehouse, data relevant to your machine learning experiments is stored. This data may include raw datasets, preprocessed data, and any associated metadata.\n",
    "\n",
    "2. Virtual Machine: You will provision a virtual machine instance in your cloud environment to establish connectivity between the VM and the data warehouse to access the required datasets.\n",
    "\n",
    "3. Experiment Tracking with MLflow: And finally, configure MLflow on the virtual machine to track machine learning experiments. Within your machine learning code running on the VM, integrate MLflow to log experiment parameters, metrics, and artifacts. And Use MLflow's APIs or command-line interface to start and manage experiments, log metrics, and save model artifacts.\n",
    "\n",
    "What are model artifacts?\n",
    "\n",
    "A model artifact refers to the tangible output or result of a machine learning model training process. These artifacts encapsulate the knowledge and learned patterns extracted from the training data, which the model uses to make predictions or perform other tasks during inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6297a2e-2a5e-4366-be20-c9348d115a3a",
   "metadata": {},
   "source": [
    "# How to track our experiments?\n",
    "\n",
    "To track machine learning experiments using MLflow, you can follow these steps:\n",
    "\n",
    "1. **Set Up MLflow Server**:\n",
    "   - Install and configure the MLflow server, which stores experiment tracking data in a database and trained models in a file storage system.\n",
    "   - The MLflow server can be hosted on a local machine or in the cloud. \n",
    "\n",
    "2. **Use MLflow UI**:\n",
    "   - Access the MLflow UI, a web interface that allows you to visualize experiment tracking data and annotate trained models.\n",
    "   - The MLflow UI provides a user-friendly way to monitor experiments, compare runs, and track model performance over time.\n",
    "\n",
    "3. MLflow CLI\n",
    "\n",
    "    - We will not focus on it, just be aware that it exists\n",
    "\n",
    "4. **Integrate MLflow into Your Code**:\n",
    "   - Import the MLflow library into your Python code and use its functions to track experiments:\n",
    "\n",
    "5. **Push Tracking Data to MLflow Server**:\n",
    "   - When your code runs, it will push experiment tracking data (parameters, metrics, model artifacts) to the MLflow server through an API.\n",
    "\n",
    "6. **Monitor Experiments**:\n",
    "   - Use the MLflow UI to monitor your experiments, view tracking data, compare different runs, and analyze model performance.\n",
    "   - The MLflow UI provides insights into experiment results and helps you make informed decisions about model improvements and optimizations.\n",
    "\n",
    "By following these steps, you can effectively track your machine learning experiments using MLflow, from logging experiment data in your code to visualizing and analyzing results in the MLflow UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb7ef78-675f-4782-aecb-b78926a03da4",
   "metadata": {},
   "source": [
    "# Track Experiment + Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1884a-76f4-4347-ae09-26b22345b3a0",
   "metadata": {},
   "source": [
    "-> GO TO ROADMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea71599-97c4-4e3a-9244-f8b2a171042e",
   "metadata": {},
   "source": [
    "-> BACK ON SLIDE: THEORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77481557-2708-4c61-8306-076d14e623d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CHART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f614552-914b-4f9d-b19c-dec684a7d1ab",
   "metadata": {},
   "source": [
    "# ML FLow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b40df-47da-43db-9703-f9ee51621e39",
   "metadata": {},
   "source": [
    "# ML Flow Server Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387ae32-e924-412a-ad07-2c056831e339",
   "metadata": {},
   "source": [
    "So this is how it is structured behind the scenes. So there is a remote host that has ML Flow running on it and it'll be connected to a SQL database that will store the metrics and parameters. But a SQL DB is not a proper way to store a model so behind the scenes it is using a bucket to store the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5234140-cfe9-4ec0-ba3a-960390385b8a",
   "metadata": {},
   "source": [
    "# Automate the model lifecycle with prefect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb34cb-bf5c-4495-859f-b7e78865c799",
   "metadata": {},
   "source": [
    "#### Manual trigger\n",
    "at the moment we still need to login to our VM or do it locally but we still need to manually run make run train\n",
    "\n",
    "#### Model Lifecycle\n",
    "but what we want is - to breakdown the models lifecycle. So let's say we wanna train our model every month. So in order to do that we need to get fresh data and check our model's performance on the new data. do we wanna retrain? do we wanna send it to production?\n",
    "\n",
    "#### get fresh data\n",
    "so in order to do that we need to get fresh data, we need to preprocess it and push it to our data warehose\n",
    "\n",
    "#### evaluate model performance\n",
    "so what we wanna do here is look at the past performance of the model so in order to do that we pull our new data from the warehouse, and run an evaluation on our model with the new data\n",
    "\n",
    "#### retrain model\n",
    "we'll retrain the model either on a VM but you can do it locally as well\n",
    "\n",
    "#### mark model for production\n",
    "and from that we want to compare the performance of the model and then maybe mark it for production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca44f73-ea8f-4aa3-a7fe-f62a9991595b",
   "metadata": {},
   "source": [
    "# Model Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62015519-ea99-42f5-9f3b-42148444803a",
   "metadata": {},
   "source": [
    "# Goal of the you guys' challenge today is:\n",
    "Implement an automated workflow to:\n",
    "- Fetch fresh data\n",
    "- Preprocess the fresh data\n",
    "- Evaluate the performance of the Production model on fresh data\n",
    "- Train a Staging model on the fresh data, in parallel to the mdoel evaluation\n",
    "- Compare the performance of the Production model vs Staging model\n",
    "- Set a threshold for a model being good enough for production\n",
    "- If neither meet the threshold notify a human who will decide whether or not to deploy the Staging model to Production and what others fixes are needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5467a34-3f11-4f42-9bf6-e4833f3b97ec",
   "metadata": {},
   "source": [
    "**We wanna decompose ou model's licycle into tasks that fit into an acyclic graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f638fb-a327-4d9d-ba4e-04b585edfc48",
   "metadata": {},
   "source": [
    "# Direct Acyclic Graph (DAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47894340-ea6a-4d33-977f-5112b454627a",
   "metadata": {},
   "source": [
    "A Directed Acyclic Graph (DAG) is a graph data structure that consists of vertices (nodes) connected by directed edges (arrows), where edges have a direction and there are no cycles.\n",
    "   - Each edge in a DAG has a direction, indicating a one-way relationship between nodes. For example, if there is an edge from node A to node B, it implies that there is a relationship or dependency from A to B.\n",
    "\n",
    "2. **Acyclic Property**:\n",
    "   - The term \"acyclic\" means that the graph does not contain any cycles. A cycle is a path in the graph that starts and ends at the same node, traversing through one or more edges. In other words, you cannot follow the edges of a DAG and return to the starting node via a directed path.\n",
    "\n",
    "3. **Vertices (Nodes)**:\n",
    "   - Nodes represent entities or elements within the graph. These can represent various entities depending on the application. For example, in a workflow DAG, nodes might represent tasks or processes.\n",
    "\n",
    "4. **Directed Paths**:\n",
    "   - A directed path is a sequence of vertices connected by directed edges, where each edge leads from one vertex to the next. In a DAG, directed paths always lead in one direction and never form a closed loop.\n",
    "\n",
    "DAGs have numerous applications such as:\n",
    "- Workflow and task scheduling: i represents dependencies between tasks or processes that need to be executed in a specific order.\n",
    "- It manages dependencies between software components or modules.\n",
    "- It represents data flows and transformations in ETL (Extract, Transform, Load) processes.\n",
    "- Version control systems: Tracking changes and dependencies in projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b26af61-60f9-4e13-84b8-5f1aa746d404",
   "metadata": {},
   "source": [
    "# Livecode\n",
    "\n",
    "So now we are gonna decompose the model lifecylce into tasks that fit into an DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83f100-9293-4231-aa59-482ac0c96531",
   "metadata": {},
   "source": [
    "# Worflow\n",
    "\n",
    "- so basically we are gonna have a taks A the has a takks B and C that happen at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75378ac7-b25f-40eb-81bb-e89e3d7cc4dd",
   "metadata": {},
   "source": [
    "# theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e0b20-06aa-447d-b45f-5a4a5c46378e",
   "metadata": {},
   "source": [
    "# Production workflow\n",
    "\n",
    "So everything has been put into a single production workflow now and all we have to do is work on sending that somewhere else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29228a94-cc0e-4082-b999-afc0a3d94732",
   "metadata": {},
   "source": [
    "# How to automate our workflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4565417-df28-4f18-99cc-d77a6296da87",
   "metadata": {},
   "source": [
    "1. **Install Prefect**:\n",
    "   - First, ensure that you have Prefect installed in your Python environment:\n",
    "     ```\n",
    "     pip install prefect\n",
    "     ```\n",
    "\n",
    "2. **Create Workflow and Tasks**:\n",
    "   - Use the Prefect Python package to define your workflow and individual tasks. Prefect provides a flexible and intuitive API for creating workflows using Python code.\n",
    "   - Define your tasks as functions or classes, and specify dependencies between tasks to create the workflow graph.\n",
    "\n",
    "3. **Set Up Prefect Server**:\n",
    "   - Install and configure Prefect Server, which is responsible for storing workflow execution parameters and results in a database.\n",
    "   - Prefect Server can be hosted on a local machine or in the cloud, depending on your requirements\n",
    "\n",
    "4. **Use Prefect UI / Prefect CLI**:\n",
    "   - Prefect provides a web interface (Prefect UI) and a command-line interface (Prefect CLI) for interacting with and managing workflows.\n",
    "   - Use the Prefect UI to parametrize, visualize, and monitor workflow execution. You can define parameters, schedule workflows, and view execution logs and results.\n",
    "   - Alternatively, use the Prefect CLI for scripting and automating workflow management tasks from the command line.\n",
    "\n",
    "5. **Run the Workflow**:\n",
    "   - Once your workflow is defined and configured, you can execute it by running the Python script that contains the workflow definition.\n",
    "   - You can also trigger workflow execution programmatically using Prefect's API or schedule it to run at specific intervals using Prefect Server or an external scheduling tool.\n",
    "\n",
    "6. **Monitor and Debug**:\n",
    "   - Monitor workflow execution and track task statuses, inputs, outputs, and execution times using Prefect UI or CLI.\n",
    "   - Debug any issues that arise during workflow execution by inspecting logs and outputs, and modify the workflow as needed to address them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432cac81-f515-430d-b548-f4096a9f2dc6",
   "metadata": {},
   "source": [
    "# Livecode ðŸš§\n",
    " \n",
    "\n",
    "ðŸŽ¯ Automate the model workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3bd716-0a5f-4358-b00e-2a435ffd0808",
   "metadata": {},
   "source": [
    "GO TO ROADMAP -> workflow.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
