{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c8e8af-b4d6-46d9-9f0d-76b7eac8602d",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12391354-3094-4035-9092-b7d4a8221cf3",
   "metadata": {},
   "source": [
    "# 1. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69108c6-901e-4fe6-9751-2cb5fe26d3ce",
   "metadata": {},
   "source": [
    "# üíª ‚úÇÔ∏è strip (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db693f74-aef0-404b-ba00-c702e610cf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['   Bonjour, comment ca va ?     ',\n",
       " '    Heyyyyy, how are you doing ?   ',\n",
       " '        Hallo, wie gehts ?     ']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    '   Bonjour, comment ca va ?     ',\n",
    "    '    Heyyyyy, how are you doing ?   ',\n",
    "    '        Hallo, wie gehts ?     '\n",
    "]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b8cd14-d2e7-4cca-a474-6c0a233a0ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bonjour, comment ca va ?',\n",
       " 'Heyyyyy, how are you doing ?',\n",
       " 'Hallo, wie gehts ?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[text.strip() for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7741a-cef2-4588-bae4-4fdc25aac5b1",
   "metadata": {},
   "source": [
    "# üíª ‚úÇÔ∏è strip (2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37679702-7b9b-43c2-8ce8-7e93263482cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abcd Who is abcd ? That's not a real name!!! abcd\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"abcd Who is abcd ? That's not a real name!!! abcd\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d37ac0-02f1-4c6b-849f-e12b69badb63",
   "metadata": {},
   "source": [
    "Here, the strip() method is used to remove leading and trailing characters from the string. In this case, it removes any occurrences of the characters 'b', 'd', 'a', or 'c' from the beginning and end of the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeef00fb-85c1-4ed7-bbaa-9a1b507ee526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Who is abcd ? That's not a real name!!! \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.strip('bdac')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca13cb6-9045-4df2-a459-1c000ca8db5a",
   "metadata": {},
   "source": [
    "# üíª üë• replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61620516-ec55-4fcb-9da8-103a0c34e3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love koalas, koalas are the cutest animals on Earth.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love koalas, koalas are the cutest animals on Earth.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9aee5e-507f-4c6e-8b34-31dc10a49b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love pandas, pandas are the cutest animals on Earth.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.replace(\"koala\", \"panda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abdb64b-41bd-4687-85e9-0d6f69ea56a4",
   "metadata": {},
   "source": [
    "# üíª ü™ö split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95409816-781e-4666-9fe1-b1e3c4b29faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"linkin park / metallica /red hot chili peppers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1654f8-0bff-4b7f-8c93-c9b60516ed92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linkin park ', ' metallica ', 'red hot chili peppers']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ec166-c040-4808-a95f-b6609d3b0cf9",
   "metadata": {},
   "source": [
    "# üíª üî° Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23eb4890-5c69-475e-be8c-0fc4b5a4e1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i LOVE football sO mUch. FOOTBALL is my passion. Who else loves fOOtBaLL ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i LOVE football sO mUch. FOOTBALL is my passion. Who else loves fOOtBaLL ?\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1bbf987-8d96-4656-98d4-625b49b23c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love football so much. football is my passion. who else loves football ?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a65edbd-268e-4d47-a2ee-5d932a2f8cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I LOVE FOOTBALL SO MUCH. FOOTBALL IS MY PASSION. WHO ELSE LOVES FOOTBALL ?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.upper() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc73e1-6fdf-4aca-8272-42e19855455e",
   "metadata": {},
   "source": [
    "# üíª üî¢ Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d22d22-bf36-4eb6-9bb9-3dd90e003bfe",
   "metadata": {},
   "source": [
    "Removing numbers during text preprocessing is often beneficial, especially for tasks like text clustering and keyphrase extraction. Here's why:\n",
    "\n",
    "- Text Clustering: Clustering algorithms, such as K-means or hierarchical clustering, group similar documents together based on their features. Including numbers in the text can introduce noise and hinder the clustering process because numbers typically do not carry semantic meaning or contribute significantly to the similarity between documents. By removing numbers, the clustering algorithm can focus on the meaningful textual content, leading to more accurate clusters that reflect the data.\n",
    "\n",
    "- Collecting Keyphrases: Keyphrase extraction involves identifying the most important phrases or terms in a document that capture its main topics or concepts. Including numbers in the text can lead to irrelevant or nonsensical keyphrases being extracted, because numbers are not informative at all in this context. Removing numbers helps ensure that the keyphrases extracted from the text are relevant and representative of its content, improving the quality of the extracted information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77607e2d-7630-452e-b093-819f98f4e2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i do not recommend this restaurant, we waited for so long, like 30 minutes, this is ridiculous'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i do not recommend this restaurant, we waited for so long, like 30 minutes, this is ridiculous\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "870d922a-3dbb-4697-a39d-94936102cf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i do not recommend this restaurant, we waited for so long, like  minutes, this is ridiculous'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = ''.join(char for char in text if not char.isdigit())\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14612099-6b20-4005-82ce-d1cd43a1e85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('a'.isdigit())\n",
    "print('5'.isdigit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88694172-6137-418b-a544-d77f849aa1c6",
   "metadata": {},
   "source": [
    "# üíª ‚ùóÔ∏è‚ùìPunctuation and Symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3850d-e93e-4855-867f-5e71292906b0",
   "metadata": {},
   "source": [
    "#### Warning: you might want to keep punctuation and symbols for authorship attribution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074c5ab6-a150-45da-9b4c-56a9229d1c0d",
   "metadata": {},
   "source": [
    "Punctuation and symbols play a crucial role in shaping an author's writing style. Factors such as the frequency and placement of commas, dashes, exclamation marks, and other symbols can be distinctive features of an author's writing.\n",
    "Retaining punctuation and symbols allows the model to capture these nuances in writing style accurately, improving the accuracy of authorship attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4247e4dc-4dcf-417c-8b66-3b593fa1a1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love bubble tea! OMG so #tasty @channel XOXO @$ ^_^ '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love bubble tea! OMG so #tasty @channel XOXO @$ ^_^ \"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b6e2199-ad41-4ec3-acd4-46bc19d18eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string # \"string\" module is already installed with Python\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8575855-948f-4a63-9d24-3365c7f16a50",
   "metadata": {},
   "source": [
    "`string.punctuation` is a string containing all ASCII punctuation characters. \n",
    "<br>\n",
    "These characters include common symbols such as exclamation marks, double quotes, hash symbols, percent signs, ampersands, apostrophes, parentheses, asterisks, plus signs, commas, hyphens, periods, slashes, colons, semicolons, less than signs, equals signs, greater than signs, question marks, at symbols, square brackets, backslashes, circumflex accents, underscores, grave accents, curly braces, vertical bars, and tildes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ffd2e36-eb56-4afe-be9c-6cddd382a327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love bubble tea OMG so tasty channel XOXO   '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for punctuation in string.punctuation:\n",
    "    text = text.replace(punctuation, '') \n",
    "    \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "050d1f68-71b9-4899-a369-23e1d8dfd203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love bubble tea OMG so tasty channel XOXO'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b132d-5f10-413f-bfd4-b27f6587bafe",
   "metadata": {},
   "source": [
    "# üíª üí™ Combo: strip + lowercase + numbers + punctuation/symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b216cf8c-6622-4e9e-8eaf-2773763b8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"   I LOVE Pizza 999 @^_^\", \n",
    "    \"  Le Wagon is amazing, take care - 666\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dce3f1f2-3bf2-4398-96e6-fade19c17b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') \n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe1403f8-b117-4ef5-8056-ee4c703199f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love pizza', 'le wagon is amazing take care']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = [basic_cleaning(sentence) for sentence in sentences]\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74224060-abe8-4ece-850c-afa857dca1c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e27d8-2a9b-4cb8-b32c-7f057100e8d8",
   "metadata": {},
   "source": [
    "\n",
    "This line of code performs a text processing operation on the variable sentence, removing any digits (numeric characters) from it.\n",
    "\n",
    "Iteration over Characters:\n",
    "\n",
    "`for char in sentence`:\n",
    "This part of the code iterates over each character in the sentence string. It uses a loop to go through every character, one by one.\n",
    "\n",
    "Conditional Filtering:\n",
    "`if not char.isdigit()`\n",
    "Inside the loop, for each character (char), there's a condition checking whether the character is not a digit. The isdigit() method is a built-in method in Python that returns True if all characters in the string are digits, otherwise it returns False. The not keyword negates this condition, so it evaluates to True if the character is not a digit.\n",
    "\n",
    "Joining Characters:`''.join(...)` The join() method is then used to concatenate the characters back together into a new string. It takes an iterable (in this case, a generator expression) as input and joins the elements together using the specified separator. In this case, the separator is an empty string '', which means the characters will be joined together without any separation between them.\n",
    "\n",
    "Generator Expression:\n",
    "`(char for char in sentence if not char.isdigit())`\n",
    "Inside the join() method, there's a generator expression. It iterates over each character in the sentence string and yields only those characters that are not digits, effectively filtering out the digits from the original string.\n",
    "\n",
    "Result:\n",
    "The final result of this line of code is a new string containing only the characters from the original sentence string that are not digits. Essentially, it removes all numeric characters from the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d447c0c-7069-46f8-8508-31cb2264fd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   I LOVE Pizza  @^_^'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ''.join(char for char in sentences[0] if not char.isdigit())\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6cefb-62cd-41f3-9f78-e7178f4a39c6",
   "metadata": {},
   "source": [
    "# üíª üîç Removing Tags with RegEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a237a5a-14cc-4772-bf18-fc48bdad0ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Le Wagon!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"<head><body>Hello Le Wagon!</body></head>\"\"\"\n",
    "cleaned_text = re.sub('<[^<]+?>','', text)\n",
    "\n",
    "print (cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a08c4055-a443-4415-a0b6-b2785bdff1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['darkvader@gmail.com', 'batman@outlook.com']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt = '''\n",
    "    This is a random text, authored by darkvader@gmail.com \n",
    "    and batman@outlook.com, WOW!\n",
    "'''\n",
    "\n",
    "re.findall('[\\w.+-]+@[\\w-]+\\.[\\w.-]+', txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35dce65-60bb-48d3-8927-d3838833a553",
   "metadata": {},
   "source": [
    "# üíª Cleaning with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bca27d-25b5-424f-98dd-483dd5c49f4a",
   "metadata": {},
   "source": [
    "Natural Language Toolkit (NLTK) is an NLP library that provides preprocessing and modeling tools for text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf433cc-c77b-4e17-bbc0-fe7b7c15313a",
   "metadata": {},
   "source": [
    "# üíª üå≤ Tokenizing - read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc0d622e-1f7a-491a-aac7-2fd10d36acaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is during our darkest moments that we must focus to see the light'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'It is during our darkest moments that we must focus to see the light'\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f43a64f9-48e3-4a19-ad50-1443097fca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'is', 'during', 'our', 'darkest', 'moments', 'that', 'we', 'must', 'focus', 'to', 'see', 'the', 'light']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "print(word_tokens) # print displays the words in one line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d310c6a-8af9-4e4f-8358-28250b03a4e4",
   "metadata": {},
   "source": [
    "# üíª üõë Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "241fc142-d662-49dc-b159-40a9c8e03b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# set(...): The list of stopwords is converted into a set. Using a set ensures that duplicate\n",
    "# stopwords are removed, and it allows for efficient membership checks.\n",
    "stop_words = set(stopwords.words('english')) # you can also choose other languages\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aa80e2-6f2d-4417-aea3-ad7802310da8",
   "metadata": {},
   "source": [
    "üï∫üèª Here is an example of a tokenized sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fd80e50-83ef-4c3c-ad54-295c88ee6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"i\", \"am\", \"going\", \"to\", \"go\", \"to\", \"the\", \n",
    "        \"club\", \"and\", \"party\", \"all\", \"night\", \"long\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297d806e-76ae-4f83-848f-a9737fba0321",
   "metadata": {},
   "source": [
    "#### ‚ùì What stopwords could be removed ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f233e21b-770e-4a33-911f-99a2a08a3da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'to', 'to', 'the', 'and', 'all']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_removed = [w for w in tokens if w in stop_words] \n",
    "stopwords_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808742a-c529-46de-9296-0db2e5510d26",
   "metadata": {},
   "source": [
    "‚ùì What are the meaningful words in this sentence ‚ùì"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b399cf-5c29-4ffd-b758-572e3428815c",
   "metadata": {},
   "source": [
    "#### üëâ What if you are not going to the party?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b9771-d99a-41fc-a6b1-b73de4ae4945",
   "metadata": {},
   "source": [
    "üò± \"not\" is also considered as a stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673cac73-0ee5-4bbc-957b-364c212048d1",
   "metadata": {},
   "source": [
    "We have to be careful with this statement when it comes to Sentiment Analysis:\n",
    "\n",
    "Stopwords removal is generally not dangerous for sentiment analysis. In fact, it can be beneficial in some cases by reducing noise and focusing on sentiment-carrying words. However, the impact of stopword removal on sentiment analysis depends on the specific context and the sentiment lexicon used. Some stopwords may carry sentiment themselves (e.x., \"not\"), so their removal could potentially affect the sentiment analysis results. So, it's essential to carefully consider the stopwords to remove and their potential impact on sentiment analysis accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772047e-e95f-4f68-97dd-00718e1132fe",
   "metadata": {},
   "source": [
    "And when it comes to author attribution, Stopword removal is also not inherently dangerous. While some stopwords may carry author-specific stylistic features, their removal is unlikely to significantly impact the accuracy of authorship attribution models. Authorship attribution relies more on higher-level stylistic features, such as vocabulary choice, sentence structure, and syntactic patterns such as punctutions, which are not heavily influenced by stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb5f4d-d8e6-4efb-86cb-1c60266739a4",
   "metadata": {},
   "source": [
    "# üíª üåê Lemmatizing - read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a65773-8ae4-4756-b440-be7d8e5384f5",
   "metadata": {},
   "source": [
    "#### üëá Look at the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcc4bbe2-d5aa-4134-bbff-57201baee93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He was RUNNING and EATING at the same time =[. He has a bad habit of swimming after playing 3 hours in the Sun =/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'He was RUNNING and EATING at the same time =[. He has a bad habit of swimming after playing 3 hours in the Sun =/'\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916a283-537a-4b24-8246-fa6c20c4b05a",
   "metadata": {},
   "source": [
    "#### üßπ Step 1: Basic Cleaning ( the method we created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07aca049-f6a5-4a5e-b036-081963c1f5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He was RUNNING and EATING at the same time =[. He has a bad habit of swimming after playing 3 hours in the Sun =/'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2c49132-6b80-48de-adfc-837551fda354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he was running and eating at the same time  he has a bad habit of swimming after playing  hours in the sun'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentence = basic_cleaning(sentence)\n",
    "cleaned_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e4c38-20fd-4c52-8f3e-405ec5287fd4",
   "metadata": {},
   "source": [
    "# üéÑ Step 2 : Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7edc640-e738-4e25-ab0e-957dbcd44f19",
   "metadata": {},
   "source": [
    "So what is tokenizing again folks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec03473c-3b01-40c8-acee-60a3f621e2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'was', 'running', 'and', 'eating', 'at', 'the', 'same', 'time', 'he', 'has', 'a', 'bad', 'habit', 'of', 'swimming', 'after', 'playing', 'hours', 'in', 'the', 'sun']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = word_tokenize(cleaned_sentence)\n",
    "print(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fbca70-0785-4f4c-9fd9-1428369762f6",
   "metadata": {},
   "source": [
    "# üõë Step 3: Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bf0aa71-ba81-4e65-b529-a1363af2b20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'eating', 'time', 'bad', 'habit', 'swimming', 'playing', 'hours', 'sun']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence_no_stopwords = [w for w in tokenized_sentence if not w in stop_words] \n",
    "print(tokenized_sentence_no_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777836d-fb54-4d1c-8da3-6ded8202979a",
   "metadata": {},
   "source": [
    "# üåê Step 4: Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea67c3c-4bfc-4caf-9368-a8cf48bf31af",
   "metadata": {},
   "source": [
    "What does lemmatizing do exactly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3873b-90cc-40bd-81c8-302ef42e2c34",
   "metadata": {},
   "source": [
    "It reduces words to their base or canonical form, known as the lemma. The lemma represents the dictionary form or root word of a given word, which allows different inflected forms of the word to be treated as a single item. For example, the lemma of \"running\" is \"run,\" and the lemma of \"better\" is \"good.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7743e5c3-a748-42ca-81b4-c7b00de75bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "# Lemmatizing the verbs\n",
    "verb_lemmatized = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos=\"v\")  # v --> verbs\n",
    "    for word in tokenized_sentence_no_stopwords\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288f798-d4b5-409f-911c-1e018af77120",
   "metadata": {},
   "source": [
    "Here, a list comprehension is used to iterate over each word in the tokenized_sentence_no_stopwords list.\n",
    "For each word, the WordNetLemmatizer().lemmatize(word, pos=\"v\") method is called. This method lemmatizes the word with the specified part-of-speech (POS) tag, which in this case is \"v\" indicating a verb.\n",
    "The lemmatized verbs are stored in the verb_lemmatized list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7794d9d-e8d0-47a7-abb0-6d46fe6822eb",
   "metadata": {},
   "source": [
    "in the same way, another list comprehension is used to iterate over each word in the verb_lemmatized list, which contains the lemmatized verbs.\n",
    "For each word, the WordNetLemmatizer().lemmatize(word, pos=\"n\") method is called with the POS tag \"n\", indicating a noun this time.\n",
    "The lemmatized nouns are stored in the noun_lemmatized list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1cbd7b7-1808-4b4a-9d6b-4360881ea5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing the nouns\n",
    "noun_lemmatized = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos=\"n\")  # n --> nouns\n",
    "    for word in verb_lemmatized\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1a93b-9e15-41c1-9f9b-43d297c0fb3e",
   "metadata": {},
   "source": [
    "Here I create a dataframe with columns for original verbs, lemmatized verbs, and lemmatized nouns. It then displays the DataFrame, allowing us to inspect the original and lemmatized forms of the words in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef7edf5d-cf35-4543-aad3-43d19c0be207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Verb</th>\n",
       "      <th>Verb Lemmatized</th>\n",
       "      <th>Noun Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>running</td>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eating</td>\n",
       "      <td>eat</td>\n",
       "      <td>eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>habit</td>\n",
       "      <td>habit</td>\n",
       "      <td>habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>swimming</td>\n",
       "      <td>swim</td>\n",
       "      <td>swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>playing</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hours</td>\n",
       "      <td>hours</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sun</td>\n",
       "      <td>sun</td>\n",
       "      <td>sun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original Verb Verb Lemmatized Noun Lemmatized\n",
       "0       running             run             run\n",
       "1        eating             eat             eat\n",
       "2          time            time            time\n",
       "3           bad             bad             bad\n",
       "4         habit           habit           habit\n",
       "5      swimming            swim            swim\n",
       "6       playing            play            play\n",
       "7         hours           hours            hour\n",
       "8           sun             sun             sun"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Original Verb': tokenized_sentence_no_stopwords,\n",
    "    'Verb Lemmatized': verb_lemmatized,\n",
    "    'Noun Lemmatized': noun_lemmatized\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d3ad7-4a7b-40b7-9514-8ba32fdb69c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df308935-126c-4b76-97e8-cc90954b11c8",
   "metadata": {},
   "source": [
    "# ü§ñ Machine Learning algorithms cannot process raw text, as it needs to be converted into numbers first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a4486-ef5a-46fd-b2c0-154159b09e2f",
   "metadata": {},
   "source": [
    "- Vectorize Texts: Use techniques such as TF-IDF (Term Frequency-Inverse Document Frequency) or word embeddings (e.g., Word2Vec, GloVe) to convert the text data into numerical vectors. TF-IDF represents each text document as a vector of word frequencies, while word embeddings represent each word as a dense vector in a continuous space. You can use libraries like scikit-learn (for TF-IDF) or TensorFlow/Keras (for word embeddings) to perform text vectorization.\n",
    "\n",
    "- Encode Target Variable: Encode the target variable (e.g., \"normal email\" vs. \"spam\") into numerical labels. For binary classification tasks like spam detection, you can use label encoding to convert categorical labels into numerical values (e.g., 0 for \"normal email\" and 1 for \"spam\").\n",
    "\n",
    "- Make Predictions: Once the model is trained, use it to make predictions on new text data. Vectorize the new text data using the same techniques used during training, and then feed the vectorized data into the trained model to get predictions. The predictions will be numerical labels representing the predicted class (e.g., 0 for \"normal email\" and 1 for \"spam\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990fda94-e492-4b3a-969b-60933cbd9ca8",
   "metadata": {},
   "source": [
    "# üíª CountVectorizer - Read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc762057-28ea-4166-9357-ae443dba3e5f",
   "metadata": {},
   "source": [
    "#### üëá Look at the following sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d02ce9a2-7397-44ae-aef5-9e4621995794",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'the young dog is running with the cat',\n",
    "    'running is good for your health',\n",
    "    'your cat is young',\n",
    "    'young young young young young cat cat cat'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56265bc-81be-4316-b467-8cb6f1245644",
   "metadata": {},
   "source": [
    "#### üë©üèª‚Äçüî¨ Let's apply the CountVectorizer to generate a Bag-of-Words representation of these four sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edd202e2-8c4f-4946-94be-dc8af6c2e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 1, 2, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "       [3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35acb136-7168-448a-aa0f-d6d9d7960f8a",
   "metadata": {},
   "source": [
    "Code Explanation:\n",
    "\n",
    "`count_vectorizer = CountVectorizer()`\n",
    "CountVectorizer is a method provided by scikit-learn for converting a collection of text documents into a matrix of token counts. Each row of the matrix represents a document, and each column represents a unique word (or token) in the entire corpus of documents.\n",
    "The CountVectorizer() function initializes a CountVectorizer object with default parameters. You can customize parameters such as tokenization rules, stopwords removal, and n-gram range, but in this case, it uses default settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f04d7-05c3-4acd-825f-4a592bafcc4d",
   "metadata": {},
   "source": [
    "In the context of natural language processing (NLP) and text analysis, a document typically refers to a single unit of text data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5116cc4-aea0-4831-955d-c4891f7699f6",
   "metadata": {},
   "source": [
    "The `toarray()` method converts the sparse matrix X into a dense array format. Sparse matrices store only non-zero entries, which is efficient for memory usage when dealing with large matrices where most entries are zero. However, dense arrays store all entries, including zeros, which makes them more memory-intensive but easier to work with for certain operations.\n",
    "By calling `toarray()`, the sparse matrix X is converted into a 2D NumPy array, where each row corresponds to a document and each column corresponds to a word, with the entry representing the count of that word in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1460823-aaa4-4692-bfa5-3a16124ddc90",
   "metadata": {},
   "source": [
    "ü§î Can you guess which column represents which word?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1927e126-b586-4552-9b1d-0b9a7cc8110c",
   "metadata": {},
   "source": [
    "# üî• As soon as the CountVectorizer is fitted to the text, you can retrieve all the words seen with get_feature_names_out():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15560b44-83f6-4b48-abca-0b06f1dc253a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'dog', 'for', 'good', 'health', 'is', 'running', 'the',\n",
       "       'with', 'young', 'your'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "845cc5cd-231c-4ecb-97ae-a4af55c15b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>is</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cat  dog  for  good  health  is  \\\n",
       "the young dog is running with the cat        1    1    0     0       0   1   \n",
       "running is good for your health              0    0    1     1       1   1   \n",
       "your cat is young                            1    0    0     0       0   1   \n",
       "young young young young young cat cat cat    3    0    0     0       0   0   \n",
       "\n",
       "                                           running  the  with  young  your  \n",
       "the young dog is running with the cat            1    2     1      1     0  \n",
       "running is good for your health                  1    0     0      0     1  \n",
       "your cat is young                                0    0     0      1     1  \n",
       "young young young young young cat cat cat        0    0     0      5     0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we turn out results into a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "vectorized_texts = pd.DataFrame(\n",
    "    X.toarray(), \n",
    "    columns = count_vectorizer.get_feature_names_out(),\n",
    "    index = texts\n",
    ")\n",
    "\n",
    "vectorized_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9a57d-7018-4e47-be17-312ac1a5d067",
   "metadata": {},
   "source": [
    "# Be aware that there are some limitations when it comes to the bag-of-words representation read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15eaac-2e70-4f9c-9b9e-130a48c83aa7",
   "metadata": {},
   "source": [
    "While Bag-of-Words (BoW) representation is effective in capturing the frequency of individual words in a document, it lacks the ability to capture the context or the sequential relationship between words. This limitation can be addressed by using N-grams.\n",
    "\n",
    "N-grams are contiguous sequences of n items (words in the context of NLP), where n refers to the number of words in the sequence. By considering sequences of words instead of individual words, N-grams capture more contextual information from the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2103db14-8bb5-449c-8380-63f59c888566",
   "metadata": {},
   "source": [
    "# 2.2. Tf-idf Representation - read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b68f48-bada-4991-abb3-10d42f67f14e",
   "metadata": {},
   "source": [
    "# Term Frequency (tf) & CountVectorizer - read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0afea37-be18-4c93-bef7-419425fcd484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>is</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cat  dog  for  good  health  is  \\\n",
       "the young dog is running with the cat        1    1    0     0       0   1   \n",
       "running is good for your health              0    0    1     1       1   1   \n",
       "your cat is young                            1    0    0     0       0   1   \n",
       "young young young young young cat cat cat    3    0    0     0       0   0   \n",
       "\n",
       "                                           running  the  with  young  your  \n",
       "the young dog is running with the cat            1    2     1      1     0  \n",
       "running is good for your health                  1    0     0      0     1  \n",
       "your cat is young                                0    0     0      1     1  \n",
       "young young young young young cat cat cat        0    0     0      5     0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadc03b-cc60-4a22-876b-f5cade5875aa",
   "metadata": {},
   "source": [
    "here we are calculating the term frequency (TF) for the word \"young\" in a document. Term frequency is a measure of how often a term (word) appears in a document relative to the total number of words in that document.\n",
    "\n",
    "The word \"young\" appears 5 times in the document.\n",
    "\n",
    "The total number of words in the document is 8.\n",
    "\n",
    "To calculate the term frequency (TF) for \"young\", you divide the number of occurrences of \"young\" by the total number of words in the document:\n",
    "\n",
    "TF(\"young\") = (Number of occurrences of \"young\") / (Total number of words in the document)\n",
    "= 5 / 8\n",
    "= 0.625\n",
    "\n",
    "So, the term frequency (TF) for the word \"young\" in the document is 0.625. This means that \"young\" accounts for 62.5% of the total words in the document. TF is often used as a feature in text analysis tasks such as information retrieval, document classification, and sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51793e-dbb2-4224-997e-ae72fff33a51",
   "metadata": {},
   "source": [
    "# Document Frequency (df) - read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5155169b-1893-4227-a968-3e9c7690c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>is</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cat  dog  for  good  health  is  \\\n",
       "the young dog is running with the cat        1    1    0     0       0   1   \n",
       "running is good for your health              0    0    1     1       1   1   \n",
       "your cat is young                            1    0    0     0       0   1   \n",
       "young young young young young cat cat cat    3    0    0     0       0   0   \n",
       "\n",
       "                                           running  the  with  young  your  \n",
       "the young dog is running with the cat            1    2     1      1     0  \n",
       "running is good for your health                  1    0     0      0     1  \n",
       "your cat is young                                0    0     0      1     1  \n",
       "young young young young young cat cat cat        0    0     0      5     0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848b1b1-2cfa-4c9c-b282-be5e7ee4caa4",
   "metadata": {},
   "source": [
    "# Summarizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d453a95-7c6b-429b-8d3f-3468b3806652",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency-Inverse Document Frequency) is a numerical statistic that reflects the importance of a term (word) within a document relative to a collection of documents (corpus). It is calculated by multiplying the term frequency (TF), which measures how often a term appears in a document, by the inverse document frequency (IDF), which measures how unique or important a term is across the entire corpus. TF-IDF assigns higher weights to terms that are frequent within a document but rare across the corpus,by highlighting terms that are both relevant and discriminative for characterizing the content of individual documents. By considering both local (within-document) and global (corpus-wide) term characteristics, TF-IDF is widely used in information retrieval, text mining, and natural language processing tasks to improve the accuracy and effectiveness of document analysis, search, and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076cf69-687d-4767-b6a4-20be644e521b",
   "metadata": {},
   "source": [
    "# 2.3. üíª TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d8f9a-10a8-4116-a5de-72ba36c17874",
   "metadata": {},
   "source": [
    "The TfidfVectorizer is a feature extraction method provided by the scikit-learn library in Python, which converts a collection of raw documents into a matrix of TF-IDF (Term Frequency-Inverse Document Frequency) features. This method combines the functionality of both CountVectorizer and TfidfTransformer into a single step, making it convenient for transforming text data into a numerical representation suitable for machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "478a0d63-c484-4410-ae47-666ac0c757a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the young dog is running with the cat',\n",
       " 'running is good for your health',\n",
       " 'your cat is young',\n",
       " 'young young young young young cat cat cat']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f88af0c-1e11-445e-85a5-4c4b844d457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e50fb389-aeee-44c6-b2ea-50dc0eb65766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>is</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.357056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.281507</td>\n",
       "      <td>0.714112</td>\n",
       "      <td>0.357056</td>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.295980</td>\n",
       "      <td>0.365594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470063</td>\n",
       "      <td>0.580622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.514496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857493</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat       dog       for      good    health        is   running  \\\n",
       "0  0.227904  0.357056  0.000000  0.000000  0.000000  0.227904  0.281507   \n",
       "1  0.000000  0.000000  0.463709  0.463709  0.463709  0.295980  0.365594   \n",
       "2  0.470063  0.000000  0.000000  0.000000  0.000000  0.470063  0.000000   \n",
       "3  0.514496  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        the      with     young      your  \n",
       "0  0.714112  0.357056  0.227904  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.365594  \n",
       "2  0.000000  0.000000  0.470063  0.580622  \n",
       "3  0.000000  0.000000  0.857493  0.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the TfidfVectorizer\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Training it on the texts\n",
    "weighted_words = pd.DataFrame(tf_idf_vectorizer.fit_transform(texts).toarray(),\n",
    "                 columns = tf_idf_vectorizer.get_feature_names_out())\n",
    "\n",
    "weighted_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec104384-c731-485e-9464-075409c4b409",
   "metadata": {},
   "source": [
    "the code demonstrates how to use the TfidfVectorizer from the scikit-learn library to transform a collection of raw text documents into a matrix of TF-IDF (Term Frequency-Inverse Document Frequency) features and then convert it into a DataFrame for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f573a5-1870-417a-9cf0-9a70b5fd2c1c",
   "metadata": {},
   "source": [
    "`weighted_words = pd.DataFrame(tf_idf_vectorizer.fit_transform(texts).toarray(),`<br>\n",
    "`columns = tf_idf_vectorizer.get_feature_names_out())`\n",
    "\n",
    "We call the fit_transform() method of the TfidfVectorizer object on the texts input. This method tokenizes the input texts, calculates the TF-IDF scores for each word in each document, and returns a sparse matrix representation of the TF-IDF features.\n",
    "We convert the sparse matrix to a dense array format using .toarray().\n",
    "Then, we create a DataFrame named weighted_words from the dense array. Each column in the DataFrame corresponds to a unique word (feature) extracted from the texts, and each row represents a document. The cell values are the corresponding TF-IDF scores for each word in each document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec088568-7a11-4bc7-984f-b320da577469",
   "metadata": {},
   "source": [
    "The Curse of Dimensionality refers to various challenges and phenomena that arise when working with high-dimensional data in machine learning and data analysis. As the number of dimensions (features) in the dataset increases, the volume of the data space grows exponentially, leading to several consequences and difficulties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621bdf9a-4b66-41bb-9bb2-3955471d700a",
   "metadata": {},
   "source": [
    "# How to use max_df and min_df parameters in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa30ab6-6813-4d27-98e7-c509e972390a",
   "metadata": {},
   "source": [
    "- max_df (Maximum Document Frequency):This parameter specifies the threshold for the maximum document frequency of terms. Terms that appear in a higher percentage of documents than the specified threshold will be ignored. If max_df is a float between 0.0 and 1.0, it represents the proportion of documents in which a term must not exceed in order to be considered. For example, max_df = 0.5 means to ignore terms that appear in more than 50% of the documents. if max_df is an integer, it represents the absolute count of documents. For example, max_df = 20 means to ignore terms that appear in more than 20 documents.\n",
    "\n",
    "- min_df (Minimum Document Frequency): This parameter specifies the threshold for the minimum document frequency of terms. Terms that appear in fewer documents than the specified threshold will be ignored. If min_df is a float between 0.0 and 1.0, it represents the proportion of documents in which a term must appear in order to be considered. For example, min_df = 0.1 means to ignore terms that appear in less than 10% of the documents. If min_df is an integer, it represents the absolute count of documents. For example, min_df = 5 means to ignore terms that appear in fewer than 5 documents.\n",
    "\n",
    "- Defaults:\n",
    "    - By default, max_df = 1.0, meaning no \"frequent\" word will be removed.\n",
    "    - By default, min_df = 0, meaning no \"infrequent\" word will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56d363af-f38a-41c7-8158-fa719fc45bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Example usage with specified max_df and min_df\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee7d8508-02d5-4799-a0c7-e186ee41d818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.5, min_df=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>TfidfVectorizer(max_df=0.5, min_df=2)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.5, min_df=2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888bff3-402f-474c-afe7-8b58230f8d9e",
   "metadata": {},
   "source": [
    "This creates a TfidfVectorizer object with a maximum document frequency of 50% and a minimum document frequency of 2 documents.\n",
    "\n",
    "Adjusting these parameters allows you to control the size and quality of the vocabulary used for text analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca45fd37-adf7-433b-a66a-999b7cd2f78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>is</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.357056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.281507</td>\n",
       "      <td>0.714112</td>\n",
       "      <td>0.357056</td>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.295980</td>\n",
       "      <td>0.365594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470063</td>\n",
       "      <td>0.580622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.514496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857493</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat       dog       for      good    health        is   running  \\\n",
       "0  0.227904  0.357056  0.000000  0.000000  0.000000  0.227904  0.281507   \n",
       "1  0.000000  0.000000  0.463709  0.463709  0.463709  0.295980  0.365594   \n",
       "2  0.470063  0.000000  0.000000  0.000000  0.000000  0.470063  0.000000   \n",
       "3  0.514496  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        the      with     young      your  \n",
       "0  0.714112  0.357056  0.227904  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.365594  \n",
       "2  0.000000  0.000000  0.470063  0.580622  \n",
       "3  0.000000  0.000000  0.857493  0.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of occurences of each word\n",
    "weighted_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6253840-1cb8-4186-9157-f9f7a14a8760",
   "metadata": {},
   "source": [
    "- X.toarray() converts the sparse matrix X (which likely represents a document-term matrix with TF-IDF or word counts) into a dense NumPy array. This operation converts the sparse matrix into a format that can be easily converted into a DataFrame.\n",
    "- columns=count_vectorizer.get_feature_names_out() retrieves the feature names (i.e., the terms or words) from the CountVectorizer object count_vectorizer. These feature names are used as column labels in the DataFrame.\n",
    "- index=texts sets the index of the DataFrame to be the texts variable. Presumably, texts contains the original raw text data used to create the document-term matrix. Each row in the DataFrame corresponds to a document, and the index labels each row with the corresponding raw text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4c26893-60e8-4cba-9952-986a62c768f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           dog  for  good  health  running  \\\n",
       "the young dog is running with the cat        1    0     0       0        1   \n",
       "running is good for your health              0    1     1       1        1   \n",
       "your cat is young                            0    0     0       0        0   \n",
       "young young young young young cat cat cat    0    0     0       0        0   \n",
       "\n",
       "                                           the  with  your  \n",
       "the young dog is running with the cat        2     1     0  \n",
       "running is good for your health              0     0     1  \n",
       "your cat is young                            0     0     1  \n",
       "young young young young young cat cat cat    0     0     0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the CountVectorizer with max_df = 2\n",
    "count_vectorizer = CountVectorizer(max_df = 2) # removing \"cat\", \"is\", \"young\"\n",
    "\n",
    "# Train it\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X = pd.DataFrame(\n",
    "    # A sparse matrix is a matrix that contains a large number of zero elements relative\n",
    "    # to its total size. In other words, most of the entries in a sparse matrix are zero.\n",
    "    X.toarray(),\n",
    "    columns = count_vectorizer.get_feature_names_out(),\n",
    "    index = texts\n",
    ")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8844e736-3c69-418a-972f-e75fcbb7ef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the young dog is running with the cat',\n",
       " 'running is good for your health',\n",
       " 'your cat is young',\n",
       " 'young young young young young cat cat cat']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14042c5c-964c-48a8-9e30-5ba8ec92fe45",
   "metadata": {},
   "source": [
    "# üíª max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b37555-f328-4abc-a025-0730d310ac63",
   "metadata": {},
   "source": [
    "# How to use \"max_features\" in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc181e-56c7-418e-ac45-190db2c4b120",
   "metadata": {},
   "source": [
    "Here, count_vectorizer is an instance of the CountVectorizer class from the scikit-learn library, which is used to convert a collection of text documents into a matrix representing the count of each word (term) in each document.\n",
    "fit_transform(texts) method fits the count_vectorizer to the texts data and transforms the text data into a document-term matrix. Each row of the matrix corresponds to a document, and each column corresponds to a unique word in the vocabulary. The values in the matrix represent the count of each word in each document.\n",
    "\n",
    "- X.toarray() converts the sparse matrix X (output from fit_transform) into a dense NumPy array. This operation is performed to convert the sparse matrix into a format suitable for creating a DataFrame.\n",
    "- columns=count_vectorizer.get_feature_names_out() retrieves the feature names (i.e., the terms or words) from the CountVectorizer object count_vectorizer. These feature names are used as column labels in the DataFrame.\n",
    "- index=texts sets the index of the DataFrame to be the texts variable. Presumably, texts contains the original raw text data used to create the document-term matrix. Each row in the DataFrame corresponds to a document, and the index labels each row with the corresponding raw text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd4cda51-949b-476e-88ec-dca796bb7fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>is</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cat  is  young\n",
       "the young dog is running with the cat        1   1      1\n",
       "running is good for your health              0   1      0\n",
       "your cat is young                            1   1      1\n",
       "young young young young young cat cat cat    3   0      5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer with the 3 most frequent words\n",
    "count_vectorizer = CountVectorizer(max_features = 3)\n",
    "\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X = pd.DataFrame(\n",
    "    X.toarray(),\n",
    "     columns = count_vectorizer.get_feature_names_out(),\n",
    "     index = texts\n",
    ")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b97169-3220-4459-ab93-d58b3ce73dc1",
   "metadata": {},
   "source": [
    "# 2.4. N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364fce0-4bd3-4a7b-9c09-14b37583be65",
   "metadata": {},
   "source": [
    "N-grams are contiguous sequences of n items (or words) from a given text or speech sample. These items can be characters, syllables, words, or even other linguistic units like morphemes or phonemes. N-grams are widely used in natural language processing (NLP) and text analysis tasks to capture local patterns and dependencies between adjacent elements in a sequence of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94cfa52b-bca2-49b1-b919-16094b775174",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_movie = [\n",
    "    \"I like the movie but NOT the actors\",\n",
    "    \"I like the actors but NOT the movie\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "997ca39a-1a1c-47c6-831b-e4dd2276b40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actors</th>\n",
       "      <th>but</th>\n",
       "      <th>like</th>\n",
       "      <th>movie</th>\n",
       "      <th>not</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I like the movie but NOT the actors</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like the actors but NOT the movie</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     actors  but  like  movie  not  the\n",
       "I like the movie but NOT the actors       1    1     1      1    1    2\n",
       "I like the actors but NOT the movie       1    1     1      1    1    2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the sentences\n",
    "count_vectorizer = CountVectorizer()\n",
    "actors_movie_vectorized = count_vectorizer.fit_transform(actors_movie)\n",
    "\n",
    "# Show the representations in a nice DataFrame\n",
    "actors_movie_vectorized = pd.DataFrame(\n",
    "    actors_movie_vectorized.toarray(),\n",
    "    columns = count_vectorizer.get_feature_names_out(),\n",
    "    index = actors_movie\n",
    ")\n",
    "\n",
    "# Show the vectorized movies\n",
    "actors_movie_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b05a0a-a12e-4a14-94d1-095fcdff61ef",
   "metadata": {},
   "source": [
    "# üò• With a unigram vectorization, we couldn't distinguish two sentences with the same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69a78741-e1c1-48b7-a1b9-5926eeaa8d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actors</th>\n",
       "      <th>but</th>\n",
       "      <th>like</th>\n",
       "      <th>movie</th>\n",
       "      <th>not</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I like the movie but NOT the actors</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like the actors but NOT the movie</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     actors  but  like  movie  not  the\n",
       "I like the movie but NOT the actors       1    1     1      1    1    2\n",
       "I like the actors but NOT the movie       1    1     1      1    1    2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_movie_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21414b49-10da-4d92-a650-5debdb1a26f2",
   "metadata": {},
   "source": [
    "While unigram vectorization is useful for capturing the occurrence of individual words in each document, it does not consider the order or sequence of words within the document. Therefore, two sentences with the same words but in different orders will have identical unigram representations.\n",
    "\n",
    "For example, consider the following two sentences:\n",
    "\n",
    "\"The quick brown fox jumps over the lazy dog.\"<br>\n",
    "\"The lazy dog jumps over the quick brown fox.\"\n",
    "<br>\n",
    "If we use unigram vectorization, both sentences will have the same vector representation because they contain the same words, regardless of the word order. This lack of consideration for word order means that unigram vectorization cannot distinguish between sentences that have the same words but different meanings or contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a44136-72e4-41c7-af87-84e1ae0871f8",
   "metadata": {},
   "source": [
    "# üë©üèª‚Äçüî¨ What about a bigram vectorization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a37ec4d-428f-4e2f-8ce1-40b7b891f129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actors but</th>\n",
       "      <th>but not</th>\n",
       "      <th>like the</th>\n",
       "      <th>movie but</th>\n",
       "      <th>not the</th>\n",
       "      <th>the actors</th>\n",
       "      <th>the movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I like the movie but NOT the actors</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like the actors but NOT the movie</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     actors but  but not  like the  movie but  \\\n",
       "I like the movie but NOT the actors           0        1         1          1   \n",
       "I like the actors but NOT the movie           1        1         1          0   \n",
       "\n",
       "                                     not the  the actors  the movie  \n",
       "I like the movie but NOT the actors        1           1          1  \n",
       "I like the actors but NOT the movie        1           1          1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the sentences\n",
    "count_vectorizer_n_gram = CountVectorizer(ngram_range = (2,2)) # BI-GRAMS\n",
    "actors_movie_vectorized_n_gram = count_vectorizer_n_gram.fit_transform(actors_movie)\n",
    "\n",
    "# Show the representations in a nice DataFrame\n",
    "actors_movie_vectorized_n_gram = pd.DataFrame(\n",
    "    actors_movie_vectorized_n_gram.toarray(),\n",
    "    columns = count_vectorizer_n_gram.get_feature_names_out(),\n",
    "    index = actors_movie\n",
    ")\n",
    "\n",
    "# Show the vectorized movies with bigrams\n",
    "actors_movie_vectorized_n_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d472efc-d8f4-4eaa-a1d1-7b1be237239c",
   "metadata": {},
   "source": [
    "üòÑ The two sentences are now distinguishable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dea8ba-8033-433d-a1e6-b4d2f35b11d0",
   "metadata": {},
   "source": [
    "To overcome this limitation and capture the sequence of words, we can use techniques such as bigram or n-gram vectorization, which consider sequences of words (e.g., pairs of consecutive words). By incorporating the order of words into the vectorization process, these techniques can capture more detailed information about the structure and semantics of the text, allowing for better differentiation between sentences with similar word compositions but different meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ccdb6216-04c4-45d6-8c54-e18201d94645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/10-Natural-Language-Processing/ham_spam_emails.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eddabc6-135f-436b-8d2a-213604db3fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
