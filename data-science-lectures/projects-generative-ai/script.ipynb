{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b349a9b-893e-4bd3-8895-033581e89104",
   "metadata": {},
   "source": [
    "# **Generative AI for Data Science**\n",
    "\n",
    "# **Structure**\n",
    "\n",
    "# **1. What is Generative AI?**\n",
    "\n",
    "# Pictures\n",
    "\n",
    "Numerous players are currently involved in the AI field. For instance, OpenAI, the creator of GPT, has recently attracted significant investment from Microsoft. This partnership has led to the integration of generative AI in search features like Bing, which now includes a ChatGPT plugin.\n",
    "\n",
    "Google, another major player, has developed its own AI models. Another noteworthy company is Anthropic, a language modeling company believed to be founded by former OpenAI employees. Many of these large generative models can be accessed on Huggingface.\n",
    "\n",
    "There are also independent companies like Jasper, known for text generation, and Midjourney, which arguably offers some of the best image generation diffusion models.\n",
    "\n",
    "GitHub Copilot is another tool that you can use to start working with generative AI. It's easily accessible to students through logo. After installing the extension, you can search for Copilot in your extensions. I've already installed it, as you can see here. If you want, you can choose to deactivate it. For example, if you type \"def add a b\", Copilot will suggest \"return a plus B\".\n",
    "\n",
    "These generative models operate by taking in input and attempting to create something they've seen many times before. They try to predict the most likely next sequence of characters or codes, the next few words in a story, or generate an image in a particular style based on other images they've seen.\n",
    "\n",
    "# **Gen AI is an umbrella term**\n",
    "\n",
    "Generative AI is a broad term. Essentially, it involves training a model that can map any input to any output. This model might be fine-tuned on a specific part of a dataset and then used to run inference. You input your prompt or data into the model, which then generates outputs with a degree of randomness. Many of these models, like ChatGPT, are stochastic. They don't just choose the most likely next word, but select it randomly from a distribution. This isn't a greedy search, which would only pick the most likely option. Instead, the model samples from a distribution of the most probable next words.\n",
    "\n",
    "Generative AI can work with images, text, and sound. All applications involve using data to pre-train a model, which then maps a prompt to an output. This could be mapping text to an image, text to a song, or a picture to a caption. Each of these models generates something new based on pre-training data.\n",
    "\n",
    "When you hear the term AI, it's good to be skeptical and understand what's going on beneath the surface. These are models with some degree of randomness, typically trained on large amounts of data.\n",
    "\n",
    "# **2. How can you use it?**\n",
    "\n",
    "# CHAT GPT\n",
    "\n",
    "One of the most accessible ways to interact with generative AI is through ChatGPT. Simply visit the ChatGPT website and start asking intuitive questions. Notably, ChatGPT has played a significant role in the current boom of generative AI. Over the past year, these language models have crossed a threshold, becoming more human-like and useful. They can serve as enhanced search engines.\n",
    "\n",
    "ChatGPT was trained on a vast amount of data, hundreds of gigabytes in fact. The training process was lengthy and involved over 175 billion parameters. The cost for inference was around $700,000 per day, though this may have increased. The training cost mentioned here applies to ChatGPT GPT-3. The training cost for GPT-4 was even higher, around the $100 billion mark.\n",
    "\n",
    "# How are these models actually trained?\n",
    "\n",
    "How are these models trained? On Transformers Day, we discussed decoder star models that predict the most likely next word. Initially, you'll start with a model that already has a solid understanding of language, such as GPT-3.\n",
    "\n",
    "This model is then fine-tuned through supervised learning using prompts, questions, and answers. The process involves feeding the model with question-answer datasets. Huggingface has a vast collection of such datasets.\n",
    "\n",
    "OpenAI created many of these examples themselves and sourced others from the web. Once the model can provide an answer to a given question, it is given a prompt to generate multiple different responses. The responses are then ranked from best to worst.\n",
    "\n",
    "This feedback data trains a reward model, a concept from reinforcement learning. The goal is to incentivize positive behaviors and potentially penalize negative ones. Once the reward model is established, it helps train the larger language models and update their weights.\n",
    "\n",
    "It would be inefficient for humans to evaluate every single output from the model, hence the use of the reward model. OpenAI, for instance, employed around 40 people for 4-5 months to work on this labeling process when training Instruct GPT, the predecessor to GPT-3.\n",
    "\n",
    "The trained language model then learns against the reward model. It generates a response to a new prompt and receives a reward or penalty based on the quality of the response. This feedback is then used to update the model weights.\n",
    "\n",
    "# **Pre-trained vs fine-tuning vs from-scratch**\n",
    "\n",
    "When dealing with large language models, an important question to consider is whether the model can meet your specific business needs, as it may lack certain awareness or capabilities. In response to this, you might question whether to use a pre-existing model, fine-tune one, or train one from scratch.\n",
    "\n",
    "# FLOWCHART\n",
    "\n",
    "This flowchart is designed to help you navigate different considerations. If you don't have a specific use case and aren't working with sensitive data, you can use pre-built ChatGPT models. We will revisit this later.\n",
    "\n",
    "Ask yourself if your task requires domain-specific expertise. If not, pre-built models can be used to embed your data into a database for querying. We will demonstrate this later in the lecture.\n",
    "\n",
    "If your task does require domain-specific expertise, meaning the language model needs a good understanding of the domain, you must then consider if you have a large amount of domain-specific data to train the model. If not, you need to collect more data or find an existing model that's already tuned, such as models trained on Twitter data or bio GPT, which has been fed with biology and medical information.\n",
    "\n",
    "If you have the time and data, you need to consider if you have the resources and knowledge to train a model from scratch, as it can be quite tricky. If not, you could find ways to reduce costs, leverage something pre-built or fine-tuned by someone else. If you do, you can fine-tune a language model.\n",
    "\n",
    "If you still struggle, and you need a high level of customization with ample domain-specific data, you could attempt to train a model from scratch. However, this is rarely necessary due to its high cost, time consumption, and technical complexity. \n",
    "\n",
    "# **Prompt engineering:**\n",
    "\n",
    "Most of the time, we work with models like GPT through APIs without making any changes. In relation to this, I want to discuss prompt engineering. This concept has gained popularity over the past year, being hailed as a game-changer for workflow and productivity. While some of the hype around prompt engineering is valid, some of it isn't.\n",
    "\n",
    "The hype has somewhat died down as these models have become more sophisticated over the past year. For instance, ChatGPT now hallucinates less and responds more accurately to specific prompts. However, there are still some tips that can enhance the outputs you get from models like ChatGPT.\n",
    "\n",
    "One key point is that ChatGPT, and similar models are excellent at tasks like role-playing. For example, you could instruct it to act as a data scientist examining a proposal for a data science project.\n",
    "\n",
    "When using these models for a specific task, be clear about what the task is, specify the inputs, and define what the outputs should be. Understand the difference between zero-shot and few-shot tasks. Zero-shot tasks involve instructing the model to perform a task without providing any examples. Few-shot tasks involve providing examples of how the task has been or should be done.\n",
    "\n",
    "Lastly, consider using a chain of thought prompting, which I'll provide an example of shortly.\n",
    "\n",
    "So to kind of give an example, I have taken a good news story from the BBC, the guitarist who saved hundreds of people on a sinking cruise liner. Very happy man there. Um, and what I'm going to do is just copy and paste, uh, these paragraphs here. I've actually got the prompt lined up here. Um, from this notebook, I'm going to copy and paste this into, uh, ChatGPT. So I've just taken it. Uh, I haven't put anything special around it. And I've said at the end summarised seven words and I ask it to summarize. That's what I get at the end. \n",
    "\n",
    "https://www.gamespot.com/articles/senuas-saga-hellblade-2-release-date/1100-6520417/\n",
    "\n",
    "As part of the Developer Direct presentation, Ninja Theory studio head Dom Matthews said Hellblade 2 focuses on delivering a \"shorter, narrative-led experience that focuses on the things we really care about.\" One of the things the team really cares about and which carries over from the first entry in the series is Hellblade 2's examination of Senua's mental state, where she \"faces a battle of overcoming the darkness within and without\" as part of a \"brutal journey of survival through the myth and torment of Viking Iceland,\" according to the game's synopsis. Senua battles with psychosis, seeing and hearing things that aren't there. It's something Ninja Theory put a lot of effort into portraying accurately, with special attention to the game's audio and the voices players will hear as they embody Senua over the course of her journey.\n",
    "\n",
    "Hellblade 2 was first revealed at The Game Awards 2019, and in the years since, Ninja Theory has slowly released a trickle of information on its sequel. The studio's use of Unreal Engine 5 has resulted in some uncannily realistic facial animations, and it has been fascinating to see the developer employ some novel DIY solutions for design challenges, like playing with their food. For an extra touch of Icelandic authenticity, Ninja Theory even teamed up with Scandinavian folk music band Heilung to produce the game's soundtrack.\n",
    "\n",
    "Beyond Hellblade 2, Microsoft also revealed a new look at other upcoming Xbox games, including the new Obsidian RPG Avowed, Oxide Games' upcoming 4X title Ara: History Untold, and MachineGames' Indiana Jones project. summarize 7 words\n",
    "\n",
    "So it's a nice summary. \n",
    "\n",
    "But when I said summarize, what I actually kind of wanted was like seven of the most important words. Let's imagine that I wanted something in a slightly different format. So here I've got this other prompt. Um, and what I'm going to do here is just walk you through it. So I'm being really explicit here with what my task is. It's to fill out the seven blank keyword slots that I provided with the most important words from this passage, limited by Backticks. And here I'm saying that this passage is being limited by Backticks is a really common way to highlight. Again, I mentioned this earlier the input to the model. So here I'm saying anything that you see between this set of backticks and this set of backticks, that is the input to, um, this specific task, uh, this can be also really useful for protecting against things like, um, prompt injection. And then at the end I've literally done response word, one word, two word, three word for word 5.647. So hopefully it will fill out each of those words for me. \n",
    "\n",
    "Your task is to fill out th seven blank key word slots that i have provided  with the most important words from this passage delimited by backticks:\n",
    "\n",
    "```As part of the Developer Direct presentation, Ninja Theory studio head Dom Matthews said Hellblade 2 focuses on delivering a \"shorter, narrative-led experience that focuses on the things we really care about.\" One of the things the team really cares about and which carries over from the first entry in the series is Hellblade 2's examination of Senua's mental state, where she \"faces a battle of overcoming the darkness within and without\" as part of a \"brutal journey of survival through the myth and torment of Viking Iceland,\" according to the game's synopsis. Senua battles with psychosis, seeing and hearing things that aren't there. It's something Ninja Theory put a lot of effort into portraying accurately, with special attention to the game's audio and the voices players will hear as they embody Senua over the course of her journey.\n",
    "\n",
    "Hellblade 2 was first revealed at The Game Awards 2019, and in the years since, Ninja Theory has slowly released a trickle of information on its sequel. The studio's use of Unreal Engine 5 has resulted in some uncannily realistic facial animations, and it has been fascinating to see the developer employ some novel DIY solutions for design challenges, like playing with their food. For an extra touch of Icelandic authenticity, Ninja Theory even teamed up with Scandinavian folk music band Heilung to produce the game's soundtrack.\n",
    "\n",
    "Beyond Hellblade 2, Microsoft also revealed a new look at other upcoming Xbox games, including the new Obsidian RPG Avowed, Oxide Games' upcoming 4X title Ara: History Untold, and MachineGames' Indiana Jones project.```\n",
    "\n",
    "Response:\n",
    "\n",
    "Word 1: Word 2: Word 3: Word 4: Word 5: Word 6: Word 7:\n",
    "\n",
    "Take the time to think through each of the words you produce and ensure that they are just one word (do not concatenate words into two) \n",
    "\n",
    "And you can see it's kind of done an okay job. \n",
    "\n",
    "So the last trick that I'm going to show you is this chain of thought idea that I mentioned before. So if I take this prompt exactly the same as what I had before, but I said take the time to think through each of the words you produce and ensure that they are just one word. Do not concatenate. Concatenate words into two. There you go. So here, I'm getting key words out of this passage. Um, and the reason it's worked is because I've just asked it to take more time. Now, obviously, the model is is not a person. It hasn't just taken all the time. It's still just reading this as a prompt and giving me an output. But consistently this chain of thought prompting like asking it to take the time to think through each steps, things like that will actually produce consistently better outputs. So you see here I've got some of the most important general concepts that we had, um, in uh, in this passage. And again, there's lots of different things you could do. You could generate text in a specific way. Um, you could do summarization, you could do, um, you could do sort of name entity recognition where you're trying to pick out, uh, key individuals or like the names of places from your text, loads and loads of different tasks can be achieved, um, with language models like ChatGPT. And these are just some tips that I'm showing you that can improve the performance of those tasks that you give it. \n",
    "\n",
    "# **3. Going beyond ChatGPT**\n",
    "\n",
    "So are you going to be spending the rest of your life, uh, taking pieces of code from ChatGPT and pasting it into whatever you're working on? Um, no. Hopefully not. Um, and there's a lot of power that can be leveraged, um, from ChatGPT by using it in its API format. \n",
    "\n",
    "# **The OpenAI API**\n",
    "\n",
    "So essentially you can just pip install, um, the OpenAI API and you can go to this page here. It will just search for the OpenAI API. Um, as a student, you will get, uh, $5 for free when you sign up. And I should also stress, it's really cheap. Everything that I'm about to do in this, uh, mini lecture is probably going to cost me, I don't know, $0.20. Um, it is unbelievably cheap to make calls to this API. Um, so once you've pip install the OpenAI API, you can get set up in your notebook. \n",
    "\n",
    "GO TO NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2b3b3-5e94-4591-be71-ddec4936f2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
