# SLIDE 1
During this first week, we will tackle the following challenges:

Writing code with Python: variables, conditions, loops, list, dict, etc.
Data collection: gather the data from different sources (CSV, API, Scraping)
SQL: a lot can already be achieved at the database level, before relying on Python to sort data. Let’s dive into some advanced queries!

# SLIDE 2
Data analysis
- Say “bye” to VS Code (for now), and “hello” to Jupyter Notebook - an IDE that allows you to add code, comments, visualisations and images inline, making it a great tool for data analysis and exploration
- Speed up your data operations thanks to vectorized computations and the numpy Python library
- tart learning the analytical and data manipulation capabilities of pandas, one of the most widely used Python data libraries

Data Visualization
- Get to know matplotlib, the Python library for data visualisation that is the “ancestor” to many other Python plotting libraries
- Learn different types of plots and their use cases, from the basics like line charts, bar charts and scatterplots, all the way to dynamic maps, ridgeline plots and more
- Practice higher level Python visualisation libraries like seaborn and plotly, allowing you to plot more diverse charts, faster

Maths
- Revisit a lot of the Agebra and Calculus we learned in school and for some of you at the university: functions, linear functions, multi variate functions, linear algebra, derivatives and so on...

- we will also revisit statistisc and probabilities: here you will see descriptive statistics which involve answering questins such as;
How can we discover underlying patterns in a bunch of numbers?
How can we represent data in useful ways?
How can we summarize the data?

we will talk about summary statistics and typical summary statistics include measures of:
Location / central tendency (e.g. mean)
Statistical Dispersion / spread (e.g. variance)
Shape of the distribution (e.g. skewness & kurtosis)
Linear correlation of two variables

Well,  we will talk about some important concepts in general like mean, mode variance, stqandard deviation and so on...

# SLIDE 3
Goals of this week:

Bring all concepts you’ve learned together
Work on an open-ended, real world problem
We will analyze a dataset provided to you.

# SLIDE 4, 5
ML Fundamentals
Data Preparation
Model Tuning
Workflow - This module is dedicated to Pipelines, the transition from notebooks to production.
Unsupervised learning
Time Series
NLP - Natural language processing (NLP) refers to the branch of computer science—and more specifically, the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can.

# SLIDE 6
Basics
Convolutional NN
Recurrent NN
NLP
Keras is an open-source software library that provides a Python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library. 

# SLIDE 7
In this module, you will impersonate a ML Engineer at WagonCab, a new taxi-app startup opening in New York!
you will create and fine-tune a machine learning model to predict the price of a ride.
Here you will be working in a isolated notebook context, hand-crafting & fine-tuning the best possible model, trained on a small, manageable subset of this dataset


# SLIDE 8,9
Opportunity sizing is a method that data scientists can use to quantify the potential impact of an initiative ahead of making the decision to invest in it. 

benchmarking is used in machine learning (ML) to refer to the evaluation and comparison of ML methods regarding their ability to learn patterns in 'benchmark' datasets that have been applied as 'standards'

In yur projects yu will dive into descriptive analisys by looking at past data to give an account of what has happened presenting your results in reports, dashboards, bar charts and other visualizations that are easily understood.